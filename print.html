<!DOCTYPE HTML>
<html lang="kr" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Async programming in Rust with async-std - kr</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="overview/async-std.html"><strong aria-hidden="true">1.1.</strong> Welcome to async-std!</a></li><li class="chapter-item expanded "><a href="overview/std-and-library-futures.html"><strong aria-hidden="true">1.2.</strong> std::future and futures-rs</a></li><li class="chapter-item expanded "><a href="overview/stability-guarantees.html"><strong aria-hidden="true">1.3.</strong> Stability guarantees</a></li></ol></li><li class="chapter-item expanded "><a href="concepts.html"><strong aria-hidden="true">2.</strong> Async concepts using async-std</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/futures.html"><strong aria-hidden="true">2.1.</strong> Futures</a></li><li class="chapter-item expanded "><a href="concepts/tasks.html"><strong aria-hidden="true">2.2.</strong> Tasks</a></li><li class="chapter-item expanded "><a href="concepts/async-read-write.html"><strong aria-hidden="true">2.3.</strong> Async read/write</a></li><li class="chapter-item expanded "><a href="concepts/streams.html"><strong aria-hidden="true">2.4.</strong> Streams and Channels</a></li></ol></li><li class="chapter-item expanded "><a href="tutorial/index.html"><strong aria-hidden="true">3.</strong> Tutorial: Implementing a chat</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tutorial/specification.html"><strong aria-hidden="true">3.1.</strong> Specification and Getting started</a></li><li class="chapter-item expanded "><a href="tutorial/accept_loop.html"><strong aria-hidden="true">3.2.</strong> Writing an Accept Loop</a></li><li class="chapter-item expanded "><a href="tutorial/receiving_messages.html"><strong aria-hidden="true">3.3.</strong> Receiving Messages</a></li><li class="chapter-item expanded "><a href="tutorial/sending_messages.html"><strong aria-hidden="true">3.4.</strong> Sending Messages</a></li><li class="chapter-item expanded "><a href="tutorial/connecting_readers_and_writers.html"><strong aria-hidden="true">3.5.</strong> Connecting Readers and Writers</a></li><li class="chapter-item expanded "><a href="tutorial/all_together.html"><strong aria-hidden="true">3.6.</strong> All Together</a></li><li class="chapter-item expanded "><a href="tutorial/clean_shutdown.html"><strong aria-hidden="true">3.7.</strong> Clean Shutdown</a></li><li class="chapter-item expanded "><a href="tutorial/handling_disconnection.html"><strong aria-hidden="true">3.8.</strong> Handling Disconnection</a></li><li class="chapter-item expanded "><a href="tutorial/implementing_a_client.html"><strong aria-hidden="true">3.9.</strong> Implementing a Client</a></li></ol></li><li class="chapter-item expanded "><a href="patterns.html"><strong aria-hidden="true">4.</strong> Async Patterns</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="patterns/small-patterns.html"><strong aria-hidden="true">4.1.</strong> TODO: Collected Small Patterns</a></li><li class="chapter-item expanded "><a href="patterns/accept-loop.html"><strong aria-hidden="true">4.2.</strong> Production-Ready Accept Loop</a></li></ol></li><li class="chapter-item expanded "><a href="security/index.html"><strong aria-hidden="true">5.</strong> Security practices</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="security/policy.html"><strong aria-hidden="true">5.1.</strong> Security Disclosures and Policy</a></li></ol></li><li class="chapter-item expanded "><a href="glossary.html"><strong aria-hidden="true">6.</strong> Glossary</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Async programming in Rust with async-std - kr</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#소개" id="소개">소개</a></h1>
<p><img src="./images/horizontal_color.svg" alt="async-std logo" /></p>
<p>이 책은 <code>async-std</code>에 대한 고수준 문서이며 이를 통해 Rust에서 비동기 프로그래밍을 어떻게 할 수 있는 지를 다룹니다. 따라서 이 책에서는 <code>async-std</code> API와 거기서 제공하는 태스크 모델에 중점을 두고 있습니다.</p>
<p>Rust 프로젝트에서 자체적인 비동기 프로그래밍을 다루는 책인 <a href="https://rust-lang.github.io/async-book/">&quot;Asynchronous Programming in Rust&quot;</a>도 있습니다. 이 책과 다른 방식으로 더 넓은 관점을 제공하기 때문에 함께 읽어보면 좋습니다.</p>
<p>번역: 제가 공부하기 위해서 꼼꼼하게 읽으려다 번역본을 올리게 되었습니다. 번역 시 적용한 원칙과 대상 버전은 아래와 같습니다.</p>
<ul>
<li>단순한 번역보다는 초보인 제가 이해할 수 있는 수준의 쉬운 설명을 추구합니다.</li>
<li>가급적이면 원문을 살리고 역자 주를 추가하겠지만 필요한 경우 의역을 사용할 수도 있습니다.</li>
<li>번역 버전: <a href="https://github.com/async-rs/async-std/commit/7eaf577b785b7436c3ae66c69e5c790e369e7564">7eaf577</a></li>
</ul>
<p>번역은 진행중입니다.</p>
<h1><a class="header" href="#async-std에-오신-것을-환영합니다" id="async-std에-오신-것을-환영합니다"><code>async-std</code>에 오신 것을 환영합니다.</a></h1>
<p><code>async-std</code>는 <a href="https://github.com/async-rs">지원하는 다른 라이브러리들</a>과 함게 비동기 프로그래밍 생활을 더 쉽게 만들어주는 라이브러리입니다. 다운스트림 라이브러리와 어플리케이션 모두에 대해서 기본적인 구현체들을 제공합니다. <code>async-std</code>라는 이름처럼 가능한 한 Rust 표준(<code>std</code>) 라이브러리에 가깝게 모델링되어 있고 모든 구성 요소를 비동기 방식의 요소로 대체하였습니다.</p>
<p><code>async-std</code>는 파일 시스템, 네트워크 작업은 물론이고 타이머와 같은 기본적인 동시성까지 모든 중요한 기본 요소들에 대한 인터페이스를 제공합니다. 또한 Rust 표준 라이브러리에 있는 <code>thread</code> 모듈과 유사한 <code>task</code> 기능도 제공합니다. 게다가 I/O 기본 요소들 뿐만 아니라 <code>Mutex</code>(역자 주: 비동기에서 사용하는 자료 구조. rust book의 <a href="https://doc.rust-lang.org/book/ch16-03-shared-state.html">해당 챕터</a> 참조.)의 <code>async/await</code> 버전에 해당하는 요소들도 있습니다.</p>
<h1><a class="header" href="#stdfuture와-futures-rs" id="stdfuture와-futures-rs"><code>std::future</code>와 <code>futures-rs</code></a></h1>
<p>Rust에는 흔히 <code>Future</code>로 불리는 타입이 두 종류입니다.</p>
<ul>
<li>첫번째는 <code>std::future::Future</code>로 Rust의 <a href="https://doc.rust-lang.org/std/future/trait.Future.html">기본 라이브러리</a>에서 나온 거죠.</li>
<li>두번째는 <code>futures::future::Future</code>로 별도의 라이브러리인 <a href="https://docs.rs/futures/0.3/futures/prelude/trait.Future.html">futures-rs 크레이트</a>에 있습니다.</li>
</ul>
<p><a href="https://docs.rs/futures/0.3/futures/prelude/trait.Future.html">futures-rs</a> 크레이트에 정의되어 있는 future가 원래 있던 구현체입니다. <code>async/await</code> 문법을 사용하기 위해서 Future 트레잇 중 핵심 부분이 Rust의 기본 라이브러리로 옮겨 갔고<code>std::future::Future</code>가 되었습니다. 그러니까 어떻게 보면 <code>std::future::Future</code>는 <code>futures::future::Future</code>의 부분집합인 셈이죠.</p>
<p><code>std::future::Future</code>와 <code>futures::future::Future</code>의 차이와 <code>async-std</code>가 사용하는 접근법을 이해하는 것은 중요합니다. Rust 사용자 입장에서 <code>std::future::Future</code> 자체를 상대하고 싶지는 않을 것입니다. <code>.await</code>을 호출하는 정도를 제외하면요. <code>std::future::Future</code> 내부에서 하는 작업들은 주로 <code>Future</code>를 구현하는 사람들에게나 관련이 있다고 보셔도 됩니다. 실수하지 않는 것이 굉장히 중요합니다. <code>Future</code> 자체에 정의되어 있던 기능들 대부분은 확장 트레잇인 <a href="https://docs.rs/futures/0.3/futures/future/trait.FutureExt.html"><code>FutureExt</code></a>로 옮겨갔습니다.. 즉 <code>futures</code> 라이브러리가 핵심 Rust 비동기 기능의 확장 역할을 한다는 것을 알 수 있습니다.</p>
<p><code>futures</code>와 마찬가지로 <code>async-std</code>도 <code>std::future::Future</code> 타입을 그대로 쓸 수 있도록 포함하고 있습니다. <code>Cargo.toml</code>에 추가하고 <code>FutureExt</code>를 가져 오면 <code>futures</code> 크레이트에서 제공하는 확장 기능들을 선택하여 쓸 수 있습니다.</p>
<h2><a class="header" href="#인터페이스와-안정성" id="인터페이스와-안정성">인터페이스와 안정성</a></h2>
<p><code>async-std</code>는 Rust 표준 라이브러리 수준으로 안정적이고 신뢰할 수 있는 라이브러리를 추구합니다. 즉 인터페이스 수준에서 <code>futures</code> 라이브러리에 의존하지 않습니다. 하지만 많은 사용자들이 <code>futures-rs</code>가 가져온 편리성을 좋아하게된 것에 대해서 고맙게 생각합니다. 그래서 <code>async-std</code>는 각 타입들에 대해서 <code>futures</code> 트레잇을 모두 구현해놓았습니다.</p>
<p>다행히 이런 접근 방식으로 인해 <code>futures</code>와 <code>async-std</code> 두 라이브러리의 관계를 완전히 유연하게 만들 수 있었습니다. 안정성에 관심이 많다면 <code>async-std</code>만 쓰면 됩니다. <code>futures</code> 라이브러리의 인터페이스를 선호한다면 두 가지를 연결해서 사용할 수도 있습니다. 두 가지 사용방식 모두 완전히 지원되니까요.</p>
<h2><a class="header" href="#async_stdfuture" id="async_stdfuture"><code>async_std::future</code></a></h2>
<p><code>async_std::future</code> 모듈에서 여러 종류의 futures를 다루는데 중요하다고 여겨지는 함수들을 지원하고 있고 안정성도 보장합니다.</p>
<h2><a class="header" href="#streams-readwriteseekbufread-트레잇" id="streams-readwriteseekbufread-트레잇">Streams, Read/Write/Seek/BufRead 트레잇</a></h2>
<p>Rust 컴파일러 상의 제약으로 <code>async_std</code> 내부에는 현재 구현이 되어 있지만 유저가 직접 구현할 수는 없습니다.</p>
<h1><a class="header" href="#stability-and-semver" id="stability-and-semver">Stability and SemVer</a></h1>
<p><code>async-std</code> follows https://semver.org/.</p>
<p>In short: we are versioning our software as <code>MAJOR.MINOR.PATCH</code>. We increase the:</p>
<ul>
<li>MAJOR version when there are incompatible API changes,</li>
<li>MINOR version when we introduce functionality in a backwards-compatible manner</li>
<li>PATCH version when we make backwards-compatible bug fixes</li>
</ul>
<p>We will provide migration documentation between major versions.</p>
<h2><a class="header" href="#future-expectations" id="future-expectations">Future expectations</a></h2>
<p><code>async-std</code> uses its own implementations of the following concepts:</p>
<ul>
<li><code>Read</code></li>
<li><code>Write</code></li>
<li><code>Seek</code></li>
<li><code>BufRead</code></li>
<li><code>Stream</code></li>
</ul>
<p>For integration with the ecosystem, all types implementing these traits also have an implementation of the corresponding interfaces in the <code>futures-rs</code> library.
Please note that our SemVer guarantees don't extend to usage of those interfaces. We expect those to be conservatively updated and in lockstep.</p>
<h2><a class="header" href="#minimum-version-policy" id="minimum-version-policy">Minimum version policy</a></h2>
<p>The current tentative policy is that the minimum Rust version required to use this crate can be increased in minor version updates. For example, if <code>async-std</code> 1.0 requires Rust 1.37.0, then <code>async-std</code> 1.0.z for all values of z will also require Rust 1.37.0 or newer. However, <code>async-std</code> 1.y for y &gt; 0 may require a newer minimum version of Rust.</p>
<p>In general, this crate will be conservative with respect to the minimum supported version of Rust. With <code>async/await</code> being a new feature though, we will track changes in a measured pace initially.</p>
<h2><a class="header" href="#security-fixes" id="security-fixes">Security fixes</a></h2>
<p>Security fixes will be applied to <em>all</em> minor branches of this library in all <em>supported</em> major revisions. This policy might change in the future, in which case we give a notice at least <em>3 months</em> ahead.</p>
<h2><a class="header" href="#credits" id="credits">Credits</a></h2>
<p>This policy is based on <a href="https://github.com/rust-lang/regex#minimum-rust-version-policy">BurntSushi's regex crate</a>.</p>
<h1><a class="header" href="#async-std를-이용한-비동기-개념" id="async-std를-이용한-비동기-개념">async-std를 이용한 비동기 개념</a></h1>
<p><a href="https://en.wikipedia.org/wiki/Futures_and_promises">Rust Futures</a>는 어렵기로 악명이 높습니다. 하지만 우리는 그렇게 생각하지 않습니다. 우리 생각에는 Rust의 Futures가 가장 쉬운 동시성 개념 중에 하나이고 직관적입니다.(역자 주:... 정말요?)</p>
<p>물론 그런 악명에는 이유가 있습니다. Futures 혼란의 근원으로 보이는 세 가지 개념을 바닥에 깔고 있습니다. 바로 지연된 계산(deferred computation), 비동기성(asynchronicity), 실행전략분리(independence of execution strategy)입니다.</p>
<p>이 개념들이 어렵지는 않지만 대부분의 사람들에게 익숙하지 않습니다. 기본 개념에서 오는 혼란이 세부 사항에 기반한 다양한 구현 과정을 거치면서 증폭됩니다. 이러한 구현에 대한 대부분의 설명은 능력자들을 대상으로 상정하고 있기 때문에 (역자 주: 저같은) 초보자들은 이해하기가 힘듭니다. 우리는 개념에 대해서 초보자도 접근가능한 개요를 제공하고 기본 요소들에 대해서 이해하기 쉽게 설명하려고 합니다.</p>
<p>Futures는 코드를 작동시키는 방법을 추상화한 개념입니다. 그 자체로는 아무 것도 하지 않습니다. 코드가 하나씩 차례대로 작동하는 명령형 언어 입장에서는 기괴한 개념이죠.</p>
<p>그렇다면 Futures는 어떻게 작동할까요? Futures는 자신을 <em>실행하는</em> 코드가 작동할 때까지 아무 것도 하지 않을 겁니다. 실행시키는 코드를 *실행자(executor)*라고 부릅시다. <em>실행자</em> 는 future코드들을 <em>언제</em> 그리고 <em>어떻게</em> 실행할 지를 결정합니다. <code>async-std::task</code> 모듈은 실행자를 상대할 수 있는 인터페이스를 제공합니다.</p>
<p>그러면 동기부여를 조금 해드리면서 시작해보도록 하죠.</p>
<h1><a class="header" href="#futures" id="futures">Futures</a></h1>
<p>Rust에서 주목할만한 점 중 하나가 <a href="https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html"><em>겁없는 동시성</em></a>입니다. 이 말은 사용자가 안전성을 포기하지 않고 동시성을 처리할 수 있는 권한을 받는다는 뜻입니다. 또한 Rust는 저수준 언어로 <em>특정 구현 전략을 선택하지 않아도</em> 겂없는 동시성을 실현할 수 있다는 뜻이기도 합니다. 즉 다른 전략의 사용자 간에 코드를 공유할 수도 있으니 나중에 <em>선택</em>할 수 있기 위해 전략을 추상화해야 한다는 뜻이도 하죠.</p>
<p>Futures <em>계산</em>을 추상화합니다. &quot;언제&quot;와 &quot;어디서&quot;와 상관없이 &quot;무엇을&quot; 처리할 지만 기술하는 거죠. 이를 위해 Futures는 코드를 작고 조합가능한 동작으로 쪼개는 것에 집중합니다. 그래서 시스템의 각 부분에서 작동시키는 거죠. 어디서 추상화할 수 있는 지를 찾기 위해 계산한다는 것이 무슨 뜻인지 살펴봅시다.</p>
<h2><a class="header" href="#send와-sync" id="send와-sync">Send와 Sync</a></h2>
<p>다행히 Rust의 동시성은 이미 잘 알려져 있고 효과적인 개념 두 가지를 가지고 있습니다. 프로그램의 동시성 부분 사이의 공유를 추상화한 것으로 바로 <code>Send</code>와 <code>Sync</code>입니다. 특히 <code>Send</code>와 <code>Sync</code> 트레잇은 모두 동시성 작업의 <em>전략</em>을 추상화하고 깔끔하게 조합하며 구현방식을 제한하지 않는 특징이 있습니다.</p>
<p>짧게 요약하자면 아래와 같습니다.</p>
<ul>
<li>
<p><code>Send</code>는 계산이 다른 동시성 계산(동시성을 다룰 때 데이터를 보내는 계산를 '센더', 전달받는 계산를 '리시버'라고 부릅니다)에 <em>전달하는 데이터</em>를 추상화하고 데이터를 보내면 보낸 측에서는 접근 권한을 잃게 합니다. 많은 프로그래밍 언어들에서 일반적으로 이 전략을 이용해서 동시성을 구현합니다. 하지만 언어 차원에서 지원하지는 않고 사용자에게 &quot;접근권한 상실&quot;을 직접 구현하게 합니다. '센더'가 전달한 데이터에 대해서 여전히 제어권을 가지고 있고 심지어 어떤 작업을 하는 것은 버그를 일으키는 대표적인 경우죠. Rust는 이 행위를 명시해서 버그가 생길 가능성을 다음과 같이 낮춰줍니다. 어떤 타입이 (적절한 마커 트레잇을 구현해서) <code>Send</code>이면 데이터를 다른 계산에 보낼 수 있습니다. 그리고 Rust의 소유권과 대여 규칙이 후속 접근을 방지합니다.</p>
</li>
<li>
<p><code>Sync</code>는 다른 동시성 계산과 <em>공유하는 데이터</em>에 대한 것입니다. <code>Send</code>와 마찬가지로 흔히 쓰는 또다른 패턴이기도 합니다. 다른 쪽에서 메모리에 쓰기 기능을 사용하는 동안 같은 위치에 쓰거나 그것을 읽는 것은 본질적으로 안전하지 않기 때문에 이런 접근은 동기화를 통해서 조정해야 합니다.<sup class="footnote-reference"><a href="#1">1</a></sup> 양측이 메모리의 위치를 동시에 사용하지 않기로 동의하는 방법은 mutex, spinlock 등 여러가지 방식이 사용되고 있습니다. 다시 말하지만 Rust는 (무려 안전하게!) 동기화 방법을 신경쓰지 않을 옵션도 제공합니다. Rust는 사용자가 <em>방법</em>은 구체화하지 않더라도 동기화가 필요한 대상이라고 표시할 수 있게 해줍니다.</p>
</li>
</ul>
<p>*&quot;쓰레드&quot;*라는 단어를 쓰는 것을 피하고 대신 &quot;계산&quot;이라고 표기한 것을 주의해주세요. <code>Send</code>와 <code>Sync</code>의 잠재력은 사용자가 <em>무엇</em>을 공유할 지에 대해서 알아야 하는 부담을 덜어주는 것입니다. 구현하는 시점에서 사용자는 지금 다루고 있는 타입에 어느 공유 방식이 적절한지만 알면 됩니다. 이를 통해 추론을 국지적으로 할 수 있고 해당 타입의 사용자가 나중에 작성하는 구현에도 영향을 받지 않게 됩니다.</p>
<p><code>Send</code>와 <code>Sync</code>는 흥미로운 방식으로 구성할 수 있으나 이 문서에 다룰 범위는 아닌 것 같습니다. <a href="https://doc.rust-lang.org/stable/book/ch16-04-extensible-concurrency-sync-and-send.html">Rust Book</a>에서 예시를 찾을 수 있습니다.</p>
<p>요약하면 Rust는 동시성 프로그램의 중요한 요소들과 데이터 공유를 안전하게 추상화할 수 있게 해줍니다. 굉장히 가벼운 방식으로요. 프로그래밍 언어 자체는 <code>Send</code>와 <code>Sync</code> 두 가지 마커만 알고 있고 그 기능을 확장해서 조금의 도움만 주기 때문입니다. 나머지는 모두 라이브러리가 처리하는 거죠.</p>
<h2><a class="header" href="#계산computation에-대한-간단한-관점" id="계산computation에-대한-간단한-관점">계산(computation)에 대한 간단한 관점</a></h2>
<p>계산에 대해서 다루면 그에 대한 <a href="https://computationbook.com/">책</a>을 한 권 쓸 수 있지만 매우 단순화시킨 관점만 이해해도 충분합니다. 계산(Computation)이란 결정에 따라 분기하고 연속으로 실행되며 결과나 오류를 생성해내는, 조합가능한 일련의 작업(operation)들입니다.</p>
<h2><a class="header" href="#계산-미루기" id="계산-미루기">계산 미루기</a></h2>
<p>위에서 다뤘듯이 <code>Send</code>와 <code>Sync</code>는 데이터에 관한 것입니다. 하지만 프로그램은 데이터 뿐만이 아니라 데이터를 <em>계산하는 것</em>에 대해서도 다룹니다. 이게 <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>Futures</code></a>가 담당하는 일입니다. 어떻게 작동하는 지는 다음 장에서 자세하게 살펴볼 것입니다. 여기서는 Futures가 무엇을 가능하게 해주는 지를 코드가 아니라 문장으로 살펴보겠습니다. Futures는 아래와 같이 작동합니다.</p>
<ul>
<li>X를 실행</li>
<li>X가 성공하면, Y를 실행</li>
</ul>
<p>Futures를 통해 위의 계획이 아래와 같이 바뀝니다:</p>
<ul>
<li>X 실행 시작</li>
<li>X가 성공하면, Y 실행 시작</li>
</ul>
<p>이번 장의 제목이 &quot;계산 미루기&quot;였던 것이 기억나나요? 그게 전부입니다. 컴퓨터에게 <em>지금</em> 무언 가를 실행하고 결정하라고 말하는 대신 무엇을 시작해야 하는지 그리고 잠재적인 이벤트에 대해서 어떻게 대응해야 하는지를 말해주는 겁니다. 잠재적인 이벤트가 바로... <code>Future</code>에서 발생하죠.</p>
<h2><a class="header" href="#시작을-지향하기" id="시작을-지향하기">시작을 지향하기</a></h2>
<p>간단한 함수를 하나 봅시다. 반환값에 주목해주세요.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::{fs::File, io, io::prelude::*};
</span><span class="boring">
</span>fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {
    let mut file = File::open(path)?;
    let mut contents = String::new();
    file.read_to_string(&amp;mut contents)?;
    Ok(contents)
}
<span class="boring">}
</span></code></pre></pre>
<p>이 함수는 언제든 부를 수 있기 때문에 호출할 때는 모든 권한을 다 가집니다. 그런데 여기에 문제가 있습니다. 사용자가 함수를 호출하는 순간, 반환값이 나올 때까지 제어권을 호출된 함수에 넘겨야 합니다.
그리고 거기서 나온 반환값은 과거에 끝난 결과를 의미합니다. 과거의 결과물에는 단점이 있습니다. 모든 결정이 이미 끝났다는 겁니다. 과거의 결과물에는 장점도 있습니다. 결과물이 명확하게 보입니다. 프로그램의 과거 계산 결과(Result)를 바로 unwrap해서 그걸로 무엇을 할 지 결정할 수 있습니다.</p>
<p>하지만 <em>계산</em>을 추상화해서 어떻게 작동시킬 지는 다른 사람이 선택할 수 있는 방식이 필요합니다. 항상 이전 계산의 결과물을 보여주는 것과는 근본적으로 호환되지 않는 방법이죠. 그래서 실행하지 않고도 계산을 <em>기술할 수</em> 있는 타입을 찾아보겠습니다. 그 함수를 다시 한 번 살펴봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::{fs::File, io, io::prelude::*};
</span><span class="boring">
</span>fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {
    let mut file = File::open(path)?;
    let mut contents = String::new();
    file.read_to_string(&amp;mut contents)?;
    Ok(contents)
}
<span class="boring">}
</span></code></pre></pre>
<p>시간의 관점에서 보면 함수를 호출하기 <em>전이나</em> 함수 결과가 반환된 <em>이후에만</em> 어떤 조치를 취할 수 있습니다. 함수가 작동하는 <em>동안에는</em> 무언가를 할 수 있는 권한을 가져가버리니까 바람직하지 않죠. 병렬 코드로 작업할 때는 그 병렬 코드를 시작할 수 있는 권한을 가져갈 수도 있습니다(코드에서 제어권을 줬으니까요).</p>
<p><a href="https://en.wikipedia.org/wiki/Thread_">쓰레드</a>를 이야기해야 할 시점이 바로 지금입니다. 하지만 쓰레드는 매우 특정한 동시성 원시자료형이라서 우리는 계속 &quot;추상화&quot;를 찾는다고 썼습니다.</p>
<p>우리가 찾고 있는 것은 미래에 나올 결과를 향해 지금 작동하는 어떤 작업을 표현하는 &quot;무언가&quot;입니다. Rust에서 &quot;무언가&quot;라고 하면 거의 대부분 트레잇이죠. <code>Future</code> 트레잇의 불완전한 정의를 살펴보는 것에서부터 시작해봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::{pin::Pin, task::{Context, Poll}};
</span><span class="boring">
</span>trait Future {
    type Output;
    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context) -&gt; Poll&lt;Self::Output&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>트레잇 정의를 자세히 살펴보면 다음 사항들을 알 수 있습니다.</p>
<ul>
<li><code>Output</code>을 이용하는 제네릭입니다.</li>
<li>현재의 계산 상태를 확인할 수 있는 <code>poll</code>이라는 함수를 제공합니다.</li>
<li>(<code>Pin</code>과 <code>Context</code>는 일단 무시해도 됩니다. 고수준에서 이해하는데는 불필요합니다.)</li>
</ul>
<p><code>poll()</code>을 호출하면 아래의 둘 중 하나가 결과로 나옵니다.</p>
<ol>
<li>계산이 완료될 경우, <code>poll</code>에서는 <a href="https://doc.rust-lang.org/std/task/enum.Poll.html#variant.Ready"><code>Poll::Ready</code></a>를 반환합니다.</li>
<li>계산이 완료되지 않은 경우, <a href="https://doc.rust-lang.org/std/task/enum.Poll.html#variant.Pending"><code>Poll::Pending</code></a>를 반환합니다.</li>
</ol>
<p>이를 통해 사용자는 <code>Future</code>가 아직 작업을 덜 끝냈는지 아니면 이미 끝내고 결과값을 반환할 수 있는 상태인지를 명시적으로 알 수 있습니다. 가장 단순한 (그러나 효율적이지 않은) 방법은 루프를 이용해서 계속 future의 상태를 확인하는 방법입니다. 최적화가 가능하며 좋은 런타임이 실제로 작동하는 방식이기도 합니다.
1번의 경우처럼 계산이 완료되었는데 <code>poll</code>을 다시 호출하는 것은 혼란을 유발할 수도 있습니다. 자세한 사항은 <a href="https://doc.rust-lang.org/std/future/trait.Future.html">futures-docs</a>를 참고하세요.</p>
<h2><a class="header" href="#async" id="async">Async</a></h2>
<p><code>Future</code> 트레잇은 Rust에 꽤 오래 존재했지만 이를 빌드하고 기술하는 것은 상당히 불편했습니다. <code>Future</code> 트레잇을 좀 더 편하게 사용하기 위해 Rust는 특별한 문법을 하나 만들었는데 바로 <code>async</code>입니다. 위에 나온 내용을 <code>async-std</code>로 구현한 예시는 아래와 같습니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{fs::File, io, io::prelude::*};
</span><span class="boring">
</span>async fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {
    let mut file = File::open(path).await?;
    let mut contents = String::new();
    file.read_to_string(&amp;mut contents).await?;
    Ok(contents)
}
<span class="boring">}
</span></code></pre></pre>
<p>놀랍게도 거의 차이가 없죠? 해야 하는 일은 함수 앞에 <code>async</code>라고 써주는 것과 <code>.await</code>라는 특별한 명령어를 두 개 더 집어넣은 것 뿐입니다.</p>
<p><code>async</code> 함수는 지연된 계산을 설정하는 역할을 합니다. 이 함수가 호출되면 <code>io::Result&lt;String&gt;</code>를 반환하는 대신 <code>Future&lt;Output = io::Result&lt;String&gt;&gt;</code>를 생성합니다.(더 정확하게는, <code>Future&lt;Output = io::Result&lt;String&gt;&gt;</code>를 구현한 타입을 생성하는 거죠.)(역자 주: 동기 함수였다면 호출 즉시 계산을 시작해서 함수에 쓰인 대로 <code>io::Result&lt;String&gt;</code>를 반환해야겠지만 <code>async</code>를 앞에 적으면 &quot;언제인지도 모르고 그리고 어디서 일지도 모르겠지만&quot; <code>io::Result&lt;String&gt;</code>를 반환할 수 있는 타입(<code>Future</code>)을 반환하는 것입니다.)</p>
<h2><a class="header" href="#await은-뭘-하는-거죠" id="await은-뭘-하는-거죠"><code>.await</code>은 뭘 하는 거죠?</a></h2>
<p><code>.await</code>이라는 접미사는 주석에 나와있는 것처럼 사용됩니다. <code>.await</code>를 사용했을 때 해당 코드는 요청된 작업(파일을 열거나 그 안에 있는 데이터를 모두 읽어들이는, 그러니까 <code>.await</code>이 붙은 코드에 따른 작업)이 마무리될 때까지 기다릴 것입니다. <code>.await?</code>도 대단한 게 아닙니다. 그냥 <code>.await</code>의 결과에 <code>?</code> 연산자를 적용하는 것일 뿐입니다. 그러면 초기 코드 예시에서 얻은 것이 무엇인가요? future를 받고는 그냥 기다리면 될까요?</p>
<p><code>.await</code>는 여기서 마커 역할을 합니다. 여기서 코드는 <code>Future</code>가 결과로 나오는 값을 생성하기를 기다리는 겁니다. 그러면 future는 어떻게 끝날까요? 신경 쓸 필요가 없습니다! <code>.await</code> 마커는 계산이 완료될 때까지 해야 하는 다른 업무 관리도 이 코드의 실행 책임을 가지고 있는 컴포넌트(보통 런타임이라고 부릅니다)에게 넘기기 때문입니다. 백그라운드에서 수행중인 작업이 완료되면 다시 이 지점으로 돌아오면 됩니다. 그래서 이런 프로그래밍 스타일을 <em>이벤트 프로그래밍</em>이라고 부릅니다. (파일을 여는 등의) 이벤트가 일어나기를 기다렸다가 그에 대해 반응(내용을 읽기)하면 되기 때문입니다.</p>
<p>이런 함수를 두 개 이상 동시에 실행하면 런타임 시스템이 현재 진행중인 <em>다른 모든 이벤트</em>를 처리하면서 대기 시간을 채우는 것이 가능합니다.</p>
<h2><a class="header" href="#결론" id="결론">결론</a></h2>
<p>결과값을 다루면서 <em>(이미 계산된 결과값이 아니라) 향후에 나올 결과값을 계산하고 있는 상태</em>를 표현할 방법을 찾아봤습니다. 거기서 폴링(polling) 개념을 다뤘죠.</p>
<p><code>Future</code>는 어떤 값을 표현하지는 않지만 <em>미래의 언젠가 값을 만들 수 있는</em> 상태입니다. 이를 구현하는 방법은 경우에 따라 매우 다양하고 복잡하지만 인터페이스는 간단합니다.</p>
<p>다음 절에서는 실제로 Future를 <em>작동</em>하기 위해서 사용할 <code>tasks</code>를 소개할 것입니다.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>아무도 쓰기를 하지 않는다는 것이 보장된다면 두 당사자가 데이터를 읽는 것은 항상 안전합니다.</p>
</div>
<h1><a class="header" href="#tasks" id="tasks">Tasks</a></h1>
<p>이제 Future가 뭔지 아니까 실행해봅시다.</p>
<p><code>async-std</code>에서는 <a href="https://docs.rs/async-std/latest/async_std/task/index.html"><code>tasks</code></a> 모듈이 Future의 실행을 담당합니다. 가장 간단한 방법은 <code>block_on</code> 함수를 이용하는 것입니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">extern crate async_std;
</span>use async_std::{fs::File, io, prelude::*, task};

async fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {
    let mut file = File::open(path).await?;
    let mut contents = String::new();
    file.read_to_string(&amp;mut contents).await?;
    Ok(contents)
}

fn main() {
    let reader_task = task::spawn(async {
        let result = read_file(&quot;data.csv&quot;).await;
        match result {
            Ok(s) =&gt; println!(&quot;{}&quot;, s),
            Err(e) =&gt; println!(&quot;Error reading file: {:?}&quot;, e)
        }
    });
    println!(&quot;Started task!&quot;);
    task::block_on(reader_task);
    println!(&quot;Stopped task!&quot;);
}
</code></pre></pre>
<p>이 코드는 파일을 읽는 코드를 실행하기 위해 <code>async_std</code>에 내장된 런타임(역자 주: async_std::task를 이용한다는 뜻입니다)에 요청하는 방식입니다. 이제 안에서 밖으로 하나씩 살펴봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{fs::File, io, prelude::*, task};
</span><span class="boring">
</span><span class="boring">async fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; {
</span><span class="boring">    let mut file = File::open(path).await?;
</span><span class="boring">    let mut contents = String::new();
</span><span class="boring">    file.read_to_string(&amp;mut contents).await?;
</span><span class="boring">    Ok(contents)
</span><span class="boring">}
</span><span class="boring">
</span>async {
    let result = read_file(&quot;data.csv&quot;).await;
    match result {
        Ok(s) =&gt; println!(&quot;{}&quot;, s),
        Err(e) =&gt; println!(&quot;Error reading file: {:?}&quot;, e)
    }
};
<span class="boring">}
</span></code></pre></pre>
<p>가장 안쪽에 있는 <code>async</code> <em>블록</em>입니다. async 블록은 <code>async</code> 함수를 호출하는데 필요하며 컴파일러에게 모든 관련 명령어를 포함하도록 지시합니다. Rust에서 모든 블록은 값을 반환하는데 <code>async</code> 블록은 <code>Future</code> 타입의 값을 반환합니다.</p>
<p>좀 더 흥미로운 부분을 살펴봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::task;
</span>task::spawn(async { });
<span class="boring">}
</span></code></pre></pre>
<p><code>async</code> 바깥 블록을 보면 <code>spawn</code>이 나왔습니다. <code>spawn</code>은 <code>Future</code>를 받아서 <code>Task</code>에서 실행하게 합니다. 그러면 결과값으로 <code>JoinHandle</code> 타입이 나옵니다. Rust의 Future는 때때로 <em>cold Future</em>라고 불립니다. (자체로는 실행을 시작할 수 없어서) Future 실행을 지시하는 무언가가 필요하기 때문입니다. Future를 실행하려면 추가적인 정보 기재가 필요합니다. 작업이 실행 중인지 아니면 완료되었는지, 메모리에 배치되어 있는지 현재 상태가 어떤지 등이죠. 이런 추가적인 정보 기재 부분을 추상화한 것이 바로 <code>Task</code>입니다.</p>
<p><code>Task</code>는 <code>쓰레드</code>와 비슷하지만 약간의 차이가 있습니다. 쓰레드는 운영체제 커널에서 조정하지만 <code>Task</code>는 프로그램에 의해서 조정됩니다. 대기해야 하는 상황이 생기면 프로그램 자체가 다시 <code>Task</code> 작동을 요청할 책임을 가지고 있습니다. 여기에 대해서는 다음에 조금 더 다룰 것입니다. 공통점도 많은데 예를 들어 <code>async_std</code>의 task도 쓰레드와 마찬가지로 이름과 ID를 가지고 있습니다.</p>
<p>여기서는 task를 <code>spawn</code>하면 task가 백그라운드에서 계속 실행된다는 것을 알면 충분합니다. <code>JoinHandle</code> 자체는 <code>Task</code>가 결과를 내놓을 때 완료되는 future입니다. <code>쓰레드</code>나 <code>join</code> 함수와 비슷하게 이제 프로그램(정확하게는 특정 호출 쓰레드)을 <em>블록</em>하고 task가 종료될때까지 기다리기 위해서 <code>block_on</code>을 호출할 수 있습니다.</p>
<h2><a class="header" href="#async_std의-task" id="async_std의-task"><code>async_std</code>의 Task</a></h2>
<p><code>async_std</code>의 Task는 가장 핵심적인 추상화된 개념 중 하나입니다. Rust의 <code>쓰레드</code>와 비슷하게 Task는 기초개념에 대한 실용적인 기능을 제공합니다. <code>Task</code>는 런타임과 관계가 있지만 그 자체로는 분리되어 있습니다. <code>async_std</code>의 Task는 여러 가지 좋은 속성들을 가지고 있기도 합니다.</p>
<ul>
<li>Task 전체를 하나의 단일 할당(single allocation)으로 처리합니다.</li>
<li>모든 Task는 결과값과 에러를 도출한 후 (Task에서 결과값으로 뱉는) <code>JoinHandle</code>을 통해 다른 Task에 전파(spawn)할 수 있는 <em>백채널</em>을 가지고 있습니다.</li>
<li>디버깅을 위한 유용한 메타데이터들을 가지고 있습니다.</li>
<li>Task를 위한 로컬 스토리지도 지원합니다.</li>
</ul>
<p><code>async_std</code>의 Task API는 명시적으로 시작하는 런타임과는 무관하게 런타임의 설정과 해체 작업을 수행합니다.</p>
<h2><a class="header" href="#blocking" id="blocking">Blocking</a></h2>
<p><code>Task</code>는 잠재적으로 실행 쓰레드를 공유하면서 <em>병렬적으로</em> 작동한다고 가정합니다. 즉, <code>std::thread::sleep</code>이나 Rust의 <code>std</code> 라이브러리의 io 함수같이 <em>운영체제 쓰레드</em>를 차단하는 작업은 그 쓰레드가 공유되는 모든 Task의 실행을 중단시킵니다. (데이터베이스 드라이버같은) 다른 라이브러리들도 비슷하게 작동합니다. <em>현재 쓰레드를 블로킹</em>하는 것은 그 자체가 나쁜 동작은 아니지만 <code>async-std</code>의 병렬적 실행모델과 잘 맞지 않습니다. 그러니까 이렇게는 쓰지 마세요.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::task;
</span>fn main() {
    task::block_on(async {
        // this is std::fs, which blocks
        std::fs::read_to_string(&quot;test_file&quot;);
    })
}
</code></pre></pre>
<p>이런 명령들을 섞어서 쓰고 싶다면 별도의 <code>쓰레드</code>로 블로킹 명령들을 보내는 걸 고려해보세요.</p>
<h2><a class="header" href="#에러와-패닉" id="에러와-패닉">에러와 패닉</a></h2>
<p>Task는 일반적인 패턴으로 오류를 보고합니다. 오류가 발생했을 때 출력 타입은 <code>Result&lt;T, E&gt;</code>이어야 합니다.</p>
<p><code>패닉</code>의 경우 <code>패닉</code>을 처리하는 코드가 있는지 여부에 따라 대응이 달라집니다. 만약 처리 코드가 없다면 프로그램이 <em>중단됩니다</em>.</p>
<p>실제로는 <code>block_on</code>이 블로킹 컴포넌트에 패닉을 전달한다는 뜻입니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018 should_panic"><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::task;
</span>fn main() {
    task::block_on(async {
        panic!(&quot;test&quot;);
    });
}
</code></pre></pre>
<pre><code class="language-text">thread 'async-task-driver' panicked at 'test', examples/panic.rs:8:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre>
<p>생성된 Task가 패닉이 되어있는 동안 Task 는 중단됩니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018 should_panic">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::task;
</span><span class="boring">use std::time::Duration;
</span>task::spawn(async {
    panic!(&quot;test&quot;);
});

task::block_on(async {
    task::sleep(Duration::from_millis(10000)).await;
})
<span class="boring">}
</span></code></pre></pre>
<pre><code class="language-text">thread 'async-task-driver' panicked at 'test', examples/panic.rs:8:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
Aborted (core dumped)
</code></pre>
<p>처음에는 이상하게 보일 수 있지만 생성된 Task에서 발생한 패닉을 조용하게 무시하는 것도 가능합니다. 지금의 동작은 생성된 Task에서 패닉을 포착했을 때의 대응방식을 사용자가 수정하여 변경할 수도 있습니다. 이를 통해 사용자는 패닉 처리 전략을 선택할 수 있습니다.</p>
<h2><a class="header" href="#결론-1" id="결론-1">결론</a></h2>
<p><code>async_std</code>는 <code>std::thread</code>와 유시한 API로 작동하는 <code>Task</code> 타입을 제공하여 유용하게 사용할 수 있습니다. 이를 통해 구조화된 방식으로 에러와 패닉을 다룰 수 있습니다.</p>
<p>Task는 별도의 병렬처리가능한 단위이며 때로는 통신도 필요합니다. 그래서 <code>Stream</code>이 나오는 것이죠.</p>
<h1><a class="header" href="#todo-async-readwrite" id="todo-async-readwrite">TODO: Async read/write</a></h1>
<h1><a class="header" href="#todo-streams" id="todo-streams">TODO: Streams</a></h1>
<h1><a class="header" href="#튜토리얼-채팅-만들기" id="튜토리얼-채팅-만들기">튜토리얼: 채팅 만들기</a></h1>
<p>채팅 서버를 만드는 것보다 간단한 게 없죠. 안 그래요?
반드시 정답은 아니더라도 채팅서버를 통해 비동기 프로그래밍의 즐거움을 느낄 수 있을 것입니다.</p>
<p>어떻게 서버가 동시에 클라이언트들의 연결을 처리할까요?</p>
<p>어떻게 서버가 클라이언트들의 연결 해제를 처리할까요?</p>
<p>어떻게 서버가 메시지들을 뿌릴까요?</p>
<p>이번 튜토리얼은 <code>async-std</code>를 이용해서 어떻게 채팅 서버를 구현하는 지 설명할 것입니다.</p>
<p><a href="https://github.com/async-rs/async-std/blob/master/examples/a-chat">레포지터리</a>에서도 튜토리얼의 내용을 찾아볼 수 있습니다.</p>
<h1><a class="header" href="#요구사항과-작업-시작" id="요구사항과-작업-시작">요구사항과 작업 시작</a></h1>
<h2><a class="header" href="#요구사항" id="요구사항">요구사항</a></h2>
<p>채팅 프로그램은 TCP를 이용한 단순한 텍스트 프로토콜을 이용합니다.
프로토콜은 utf-8 메시지로 구성되고 <code>\n</code>으로 구분합니다.</p>
<p>클라이언트는 서버에 접속해서 첫 줄에 로그인 정보를 보냅니다.
그리고 클라이언트는 다음 문법에 맞춰서 다른 클라이언트들에게 메시지를 보냅니다.</p>
<pre><code class="language-text">login1, login2, ... loginN: message
</code></pre>
<p>개별 클라이언트들은 <code>from login: message</code>라는 메시지를 받습니다.</p>
<p>아마도 세션은 이런 식으로 이뤄지겠죠.</p>
<pre><code class="language-text">On Alice's computer:   |   On Bob's computer:

&gt; alice                |   &gt; bob
&gt; bob: hello               &lt; from alice: hello
                       |   &gt; alice, bob: hi!
                           &lt; from bob: hi!
&lt; from bob: hi!        |
</code></pre>
<p>채팅 서버의 가장 큰 문제는 수많은 동시 접속을 추적하는 것입니다.
채팅 클라이언트의 가장 큰 문제는 동시에 일어나는 메시지 수신, 발신 그리고 사용자의 타이핑까지 관리하는 것입니다.</p>
<h2><a class="header" href="#작업-시작" id="작업-시작">작업 시작</a></h2>
<p>먼저 Cargo 프로젝트를 만들어봅시다.</p>
<pre><code class="language-bash">$ cargo new a-chat
$ cd a-chat
</code></pre>
<p>그리고 아래의 내용을 <code>Cargo.toml</code>에 추가하세요.</p>
<pre><code class="language-toml">[dependencies]
futures = &quot;0.3.0&quot;
async-std = &quot;1&quot;
</code></pre>
<h2><a class="header" href="#수락-루프-작성" id="수락-루프-작성">수락 루프 작성</a></h2>
<p>서버의 얼개부터 구현해보겠습니다. TCP 소켓을 주소에 바인딩하고 연결 수락을 시작하는 루프죠.</p>
<p>먼저 사용할 라이브러리 요소들부터 추가해봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span>use async_std::{
    prelude::*, // 1
    task, // 2
    net::{TcpListener, ToSocketAddrs}, // 3
};

type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;; // 4
<span class="boring">}
</span></code></pre></pre>
<ol>
<li><code>prelude</code>는 future와 stream으로 작업하기 위해 필요한 트레잇들을 담고 있습니다.</li>
<li><code>task</code> 모듈은 대략 <code>std::thread</code> 모듈과 비슷하지만 task 모듈이 훨씬 더 가볍습니다.
단일 쓰레드는 여러 개의 task를 처리할 수 있습니다.</li>
<li>소켓 타입에서는 <code>async_std</code>의 <code>TcpListener</code>를 사용할 것입니다. 이는 <code>std::net::TcpListener</code>와 비슷하지만 논블로킹이고 <code>async</code> API를 사용합니다.</li>
<li>이번 예제에서는 포괄적인 에러 처리는 구현하지 않을 것입니다.
에러를 전파하기 위해서 boxed 에러 트레잇 객체를 사용합니다.
std 라이브러리에 <code>From&lt;&amp;'_ str&gt; for Box&lt;dyn Error&gt;</code> 구현이 있다는 것을 알고 있었나요? <code>?</code> 연산자를 문자열과 함께 사용할 수 있습니다.</li>
</ol>
<p>이제 서버의 수락 루프를 작성할 수 있게 되었습니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; { // 1

    let listener = TcpListener::bind(addr).await?; // 2
    let mut incoming = listener.incoming();
    while let Some(stream) = incoming.next().await { // 3
        // TODO
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li><code>accept_loop</code> 함수에 <code>async</code>를 표시하면 함수 안에서 <code>.await</code> 문법을 쓸 수 있습니다.</li>
<li><code>TcpListener::bind</code> 호출은 Future를 반환합니다. 여기에 <code>.await</code>를 사용해서 <code>Result</code>를 받을 수 있고 <code>?</code> 연산자를 적용하면 <code>TcpListener</code>가 나옵니다.
어떻게 <code>.await</code>와 <code>?</code> 연산자가 어떻게 함께 잘 작동하는지 꼭 확인합시다.
정확하게 <code>std::net::TcpListener</code>가 작동하는 방법인데 여기에 <code>.await</code>만 추가되었습니다.
<code>std</code> API를 그대로 복제하는 것이 <code>async_std</code>의 명확한 디자인 목표이기 때문입니다.</li>
<li>이제 우리는 소켓으로 들어오는 값들을 반복하고 싶습니다. <code>std</code>에서는 아래와 같이 작동하는 것처럼요.</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2018 should_panic">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let listener: std::net::TcpListener = unimplemented!();
for stream in listener.incoming() {
}
<span class="boring">}
</span></code></pre></pre>
<p>하지만 안타깝게도 이 기능은 <code>async</code>에서 아직 작동하지 않습니다. Rust에서 <code>async</code> for-반복문을 지원하지 않기 때문입니다.
따라서 <code>while let Some(item) = iter.next().await</code> 패턴을 사용해서 아래와 같이 루프를 수동으로 구현해야 합니다.</p>
<p>마지막으로 main을 추가하겠습니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span><span class="boring">async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; { // 1
</span><span class="boring">    let listener = TcpListener::bind(addr).await?; // 2
</span><span class="boring">    let mut incoming = listener.incoming();
</span><span class="boring">    while let Some(stream) = incoming.next().await { // 3
</span><span class="boring">        // TODO
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span>// main
fn run() -&gt; Result&lt;()&gt; {
    let fut = accept_loop(&quot;127.0.0.1:8080&quot;);
    task::block_on(fut)
}
<span class="boring">}
</span></code></pre></pre>
<p>여기서 깨달아야 할 중요한 점은 다른 언어들과는 다르게 Rust에서는 비동기 함수를 호출해도 실행이 되지 <strong>않는다는</strong> 점입니다.
비동기 함수는 비활성 상태 머신인 Future를 만들 뿐입니다.
비동기 함수에서 Future 상태 머신을 단계 별로 실행하려면 <code>.await</code>를 사용해야 합니다.
비동기가 아닌 함수에서는 Future를 실행하려면 이를 실행자(executor)에게 전달해야 합니다.
이 경우에는 <code>task::block_on</code>을 이용해서 Future를 현재의 쓰레드에서 실행하고 완료될 때까지 나머지 작업을 블로킹하게 됩니다.</p>
<h2><a class="header" href="#메시지-받기" id="메시지-받기">메시지 받기</a></h2>
<p>프로토콜에서 수신부를 구현해봅시다.
아래 세 가지를 해야 합니다.</p>
<ol>
<li>받은 <code>TcpStream</code>을 <code>\n</code> 단위로 분리해서 utf-8 단위의 바이트로 디코딩</li>
<li>첫번째 줄은 login으로 처리</li>
<li>나머지는 <code>login: message</code>으로 파싱</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span>use async_std::{
    io::BufReader,
    net::TcpStream,
};

async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let listener = TcpListener::bind(addr).await?;
    let mut incoming = listener.incoming();
    while let Some(stream) = incoming.next().await {
        let stream = stream?;
        println!(&quot;Accepting from: {}&quot;, stream.peer_addr()?);
        let _handle = task::spawn(connection_loop(stream)); // 1
    }
    Ok(())
}

async fn connection_loop(stream: TcpStream) -&gt; Result&lt;()&gt; {
    let reader = BufReader::new(&amp;stream); // 2
    let mut lines = reader.lines();

    let name = match lines.next().await { // 3
        None =&gt; Err(&quot;peer disconnected immediately&quot;)?,
        Some(line) =&gt; line?,
    };
    println!(&quot;name = {}&quot;, name);

    while let Some(line) = lines.next().await { // 4
        let line = line?;
        let (dest, msg) = match line.find(':') { // 5
            None =&gt; continue,
            Some(idx) =&gt; (&amp;line[..idx], line[idx + 1 ..].trim()),
        };
        let dest: Vec&lt;String&gt; = dest.split(',').map(|name| name.trim().to_string()).collect();
        let msg: String = msg.to_string();
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>
<p><code>task::spawn</code> 함수를 이용해서 각 클라이언트와 작업하기 위한 독립적인 Task를 생성합니다.
즉, 클라이언트를 수락하면 즉시 <code>accept_loop</code>이 다음 클라이언트를 기다리기 시작하는 것입니다.
이벤트 주도 아키텍처의 핵심 이점입니다. 동시에 많은 클라이언트에 서비스를 제공하지만 하드웨어 쓰레드를 많이 쓰지는 않죠.</p>
</li>
<li>
<p>운 좋게도 &quot;바이트 스트림을 행으로 분할&quot;하는 기능은 이미 구현이 되어 있습니다.
<code>.lines()</code>를 호출하면 <code>String</code>의 스트림을 반환합니다.</p>
</li>
<li>
<p>이제 첫번째 줄에서 로그인을 얻을 수 있습니다.</p>
</li>
<li>
<p>그리고 다시 한 번, 수동 async 루프를 구현합니다.(역자 주: 아직 Rust에서 async의 for 루프를 지원하지 않습니다.)</p>
</li>
<li>
<p>마지막으로 각 행을 대상 로그인 목록과 메시지 자체로 파싱합니다.</p>
</li>
</ol>
<h2><a class="header" href="#에러-관리" id="에러-관리">에러 관리</a></h2>
<p>위의 솔루션이 가지는 중요한 문제는 <code>connection_loop</code>에서 오류를 올바르게 전파하지만 마지막에는 그냥 던져버린다는 것입니다.
<code>task::spawn</code>이 나왔다고 즉시 오류를 반환하지 않습니다.(사실 그렇게 할 수가 없습니다. Future의 작업이 완료되는 것이 먼저 필요하니까요.)
Task가 결합될 때까지 기다리도록 다음과 같이 수정할 수 있습니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">#![feature(async_closure)]
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{
</span><span class="boring">    io::BufReader,
</span><span class="boring">    net::{TcpListener, TcpStream, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span><span class="boring">async fn connection_loop(stream: TcpStream) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let reader = BufReader::new(&amp;stream); // 2
</span><span class="boring">    let mut lines = reader.lines();
</span><span class="boring">
</span><span class="boring">    let name = match lines.next().await { // 3
</span><span class="boring">        None =&gt; Err(&quot;peer disconnected immediately&quot;)?,
</span><span class="boring">        Some(line) =&gt; line?,
</span><span class="boring">    };
</span><span class="boring">    println!(&quot;name = {}&quot;, name);
</span><span class="boring">
</span><span class="boring">    while let Some(line) = lines.next().await { // 4
</span><span class="boring">        let line = line?;
</span><span class="boring">        let (dest, msg) = match line.find(':') { // 5
</span><span class="boring">            None =&gt; continue,
</span><span class="boring">            Some(idx) =&gt; (&amp;line[..idx], line[idx + 1 ..].trim()),
</span><span class="boring">        };
</span><span class="boring">        let dest: Vec&lt;String&gt; = dest.split(',').map(|name| name.trim().to_string()).collect();
</span><span class="boring">        let msg: String = msg.trim().to_string();
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">async move |stream| {
</span>let handle = task::spawn(connection_loop(stream));
handle.await?
<span class="boring">};
</span><span class="boring">}
</span></code></pre></pre>
<p><code>.await</code>을 통해 클라이언트가 종료할 때까지 기다리고 <code>?</code> 연산자로 결과값을 전파합니다.</p>
<p>하지만 이 솔루션에도 여전히 두 가지 문제가 있습니다!
<em>첫 번째</em>는 클라이언트 작업이 완료될 때까지 기다리는 방식이라서 한 번에 클라이언트를 하나만 처리할 수 있다는 점입니다. 그러면 비동기의 목적과 완전히 어긋나죠.
<em>두 번째</em>는 만약 클라이언트에 IO 에러가 발생하면 서버가 즉시 종료됩니다.
즉 하나의 피어만 연결이 불안정해도 모든 채팅방이 다운되는 거죠.</p>
<p>이 경우 클라이언트 오류를 처리하는 올바른 방법은 로그를 남기고 다른 클라이언트들에 서비스를 제공하는 것입니다.
이를 위해 헬퍼 함수를 사용해봅시다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use async_std::{
</span><span class="boring">    io,
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span>fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
where
    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
{
    task::spawn(async move {
        if let Err(e) = fut.await {
            eprintln!(&quot;{}&quot;, e)
        }
    })
}
<span class="boring">}
</span></code></pre></pre>
<h2><a class="header" href="#메시지-보내기" id="메시지-보내기">메시지 보내기</a></h2>
<p>이제 나머지 절반인 메시지 전송을 구현할 차례입니다.
전송을 구현하는 가장 확실한 방법은 각 <code>connection_loop</code>에 서로의 클라이언트 <code>TcpStream</code>에 대한 쓰기 권한을 주는 것입니다.
이렇게 하면 클라이언트가 수신자에게 직접 메시지를 <code>.write_all</code>을 이용해서 기록할 수 있게 됩니다.
하지만 이것은 잘못된 방법입니다. 만약 Alice가 <code>bob: foo</code>라고 보내고 Charley가 <code>bob: bar</code>라고 보냈을 때 Bob은 <code>fobaor</code>를 받을 수도 있기 때문입니다.(역자 주: 작성이 동시에 이뤄져서 말들이 섞일(<code>foo</code>, <code>bar</code> -&gt; <code>fo</code>+<code>ba</code>+<code>o</code>+<code>r</code>) 수 있다는 뜻입니다. 하나의 쓰기가 완료되고 그 다음에 써야 하는 거죠.)
소켓을 통해서 메시지를 보내는 것은 여러 시스템 호출이 필요할 수도 있습니다. 그래서 <code>.write_all</code> 두 개를 동시에 호출하면 서로 간섭이 일어날 수도 있습니다.</p>
<p>가장 중요한 원칙은 하나의 Task만 각 <code>TcpStream</code>에 작성해야 한다는 것입니다.
그러면 채널을 통해 메시지를 받아서 소켓을 통해 메시지를 기록하는 <code>connection_writer_loop</code> Task를 만들어 봅시다.
이 Task는 메시지 직렬화 지점에 해당합니다.
Alice와 Charley가 Bob에게 동시에 두 메시지를 보냈을 때 Bob은 채널에 도착한 것과 동일한 순서로 메시지를 보게 됩니다.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::TcpStream,
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span>use futures::channel::mpsc; // 1
use futures::sink::SinkExt;
use std::sync::Arc;

<span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span>type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;; // 2
type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;

async fn connection_writer_loop(
    mut messages: Receiver&lt;String&gt;,
    stream: Arc&lt;TcpStream&gt;, // 3
) -&gt; Result&lt;()&gt; {
    let mut stream = &amp;*stream;
    while let Some(msg) = messages.next().await {
        stream.write_all(msg.as_bytes()).await?;
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li><code>futures</code> 크레잇에서 channel을 사용합니다.</li>
<li>단순하게 하기 위해 이번 튜토리얼에서는 <code>unbounded</code> 채널을 사용하고 백프레셔에 대해서는 다루지 않겠습니다.</li>
<li><code>connection_loop</code>와 <code>connection_writer_loop</code>는 똑같은 <code>TcpStream</code>을 공유합니다. 그 TcpStream을 <code>Arc</code>에 넣었습니다.
<code>client</code>는 스트림에서 읽기만 하고 <code>connection_writer_loop</code>는 스트림에서 쓰기만 하기 때문에 서로 다툴 일이 없다는 점을 주목하세요.</li>
</ol>
<h2><a class="header" href="#connecting-readers-and-writers" id="connecting-readers-and-writers">Connecting Readers and Writers</a></h2>
<p>So how do we make sure that messages read in <code>connection_loop</code> flow into the relevant <code>connection_writer_loop</code>?
We should somehow maintain a <code>peers: HashMap&lt;String, Sender&lt;String&gt;&gt;</code> map which allows a client to find destination channels.
However, this map would be a bit of shared mutable state, so we'll have to wrap an <code>RwLock</code> over it and answer tough questions of what should happen if the client joins at the same moment as it receives a message.</p>
<p>One trick to make reasoning about state simpler comes from the actor model.
We can create a dedicated broker task which owns the <code>peers</code> map and communicates with other tasks using channels.
By hiding <code>peers</code> inside such an &quot;actor&quot; task, we remove the need for mutexes and also make the serialization point explicit.
The order of events &quot;Bob sends message to Alice&quot; and &quot;Alice joins&quot; is determined by the order of the corresponding events in the broker's event queue.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::TcpStream,
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">use futures::channel::mpsc;
</span><span class="boring">use futures::sink::SinkExt;
</span><span class="boring">use std::sync::Arc;
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
</span><span class="boring">type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;
</span><span class="boring">
</span><span class="boring">async fn connection_writer_loop(
</span><span class="boring">    mut messages: Receiver&lt;String&gt;,
</span><span class="boring">    stream: Arc&lt;TcpStream&gt;,
</span><span class="boring">) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let mut stream = &amp;*stream;
</span><span class="boring">    while let Some(msg) = messages.next().await {
</span><span class="boring">        stream.write_all(msg.as_bytes()).await?;
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
</span><span class="boring">where
</span><span class="boring">    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
</span><span class="boring">{
</span><span class="boring">    task::spawn(async move {
</span><span class="boring">        if let Err(e) = fut.await {
</span><span class="boring">            eprintln!(&quot;{}&quot;, e)
</span><span class="boring">        }
</span><span class="boring">    })
</span><span class="boring">}
</span><span class="boring">
</span>use std::collections::hash_map::{Entry, HashMap};

#[derive(Debug)]
enum Event { // 1
    NewPeer {
        name: String,
        stream: Arc&lt;TcpStream&gt;,
    },
    Message {
        from: String,
        to: Vec&lt;String&gt;,
        msg: String,
    },
}

async fn broker_loop(mut events: Receiver&lt;Event&gt;) -&gt; Result&lt;()&gt; {
    let mut peers: HashMap&lt;String, Sender&lt;String&gt;&gt; = HashMap::new(); // 2

    while let Some(event) = events.next().await {
        match event {
            Event::Message { from, to, msg } =&gt; {  // 3
                for addr in to {
                    if let Some(peer) = peers.get_mut(&amp;addr) {
                        let msg = format!(&quot;from {}: {}\n&quot;, from, msg);
                        peer.send(msg).await?
                    }
                }
            }
            Event::NewPeer { name, stream } =&gt; {
                match peers.entry(name) {
                    Entry::Occupied(..) =&gt; (),
                    Entry::Vacant(entry) =&gt; {
                        let (client_sender, client_receiver) = mpsc::unbounded();
                        entry.insert(client_sender); // 4
                        spawn_and_log_error(connection_writer_loop(client_receiver, stream)); // 5
                    }
                }
            }
        }
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>The broker task should handle two types of events: a message or an arrival of a new peer.</li>
<li>The internal state of the broker is a <code>HashMap</code>.
Note how we don't need a <code>Mutex</code> here and can confidently say, at each iteration of the broker's loop, what is the current set of peers</li>
<li>To handle a message, we send it over a channel to each destination</li>
<li>To handle a new peer, we first register it in the peer's map ...</li>
<li>... and then spawn a dedicated task to actually write the messages to the socket.</li>
</ol>
<h2><a class="header" href="#all-together" id="all-together">All Together</a></h2>
<p>At this point, we only need to start the broker to get a fully-functioning (in the happy case!) chat:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span>use async_std::{
    io::BufReader,
    net::{TcpListener, TcpStream, ToSocketAddrs},
    prelude::*,
    task,
};
use futures::channel::mpsc;
use futures::sink::SinkExt;
use std::{
    collections::hash_map::{HashMap, Entry},
    sync::Arc,
};

type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;

// main
fn run() -&gt; Result&lt;()&gt; {
    task::block_on(accept_loop(&quot;127.0.0.1:8080&quot;))
}

fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
where
    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
{
    task::spawn(async move {
        if let Err(e) = fut.await {
            eprintln!(&quot;{}&quot;, e)
        }
    })
}

async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let listener = TcpListener::bind(addr).await?;

    let (broker_sender, broker_receiver) = mpsc::unbounded(); // 1
    let _broker_handle = task::spawn(broker_loop(broker_receiver));
    let mut incoming = listener.incoming();
    while let Some(stream) = incoming.next().await {
        let stream = stream?;
        println!(&quot;Accepting from: {}&quot;, stream.peer_addr()?);
        spawn_and_log_error(connection_loop(broker_sender.clone(), stream));
    }
    Ok(())
}

async fn connection_loop(mut broker: Sender&lt;Event&gt;, stream: TcpStream) -&gt; Result&lt;()&gt; {
    let stream = Arc::new(stream); // 2
    let reader = BufReader::new(&amp;*stream);
    let mut lines = reader.lines();

    let name = match lines.next().await {
        None =&gt; Err(&quot;peer disconnected immediately&quot;)?,
        Some(line) =&gt; line?,
    };
    broker.send(Event::NewPeer { name: name.clone(), stream: Arc::clone(&amp;stream) }).await // 3
        .unwrap();

    while let Some(line) = lines.next().await {
        let line = line?;
        let (dest, msg) = match line.find(':') {
            None =&gt; continue,
            Some(idx) =&gt; (&amp;line[..idx], line[idx + 1 ..].trim()),
        };
        let dest: Vec&lt;String&gt; = dest.split(',').map(|name| name.trim().to_string()).collect();
        let msg: String = msg.to_string();

        broker.send(Event::Message { // 4
            from: name.clone(),
            to: dest,
            msg,
        }).await.unwrap();
    }
    Ok(())
}

async fn connection_writer_loop(
    mut messages: Receiver&lt;String&gt;,
    stream: Arc&lt;TcpStream&gt;,
) -&gt; Result&lt;()&gt; {
    let mut stream = &amp;*stream;
    while let Some(msg) = messages.next().await {
        stream.write_all(msg.as_bytes()).await?;
    }
    Ok(())
}

#[derive(Debug)]
enum Event {
    NewPeer {
        name: String,
        stream: Arc&lt;TcpStream&gt;,
    },
    Message {
        from: String,
        to: Vec&lt;String&gt;,
        msg: String,
    },
}

async fn broker_loop(mut events: Receiver&lt;Event&gt;) -&gt; Result&lt;()&gt; {
    let mut peers: HashMap&lt;String, Sender&lt;String&gt;&gt; = HashMap::new();

    while let Some(event) = events.next().await {
        match event {
            Event::Message { from, to, msg } =&gt; {
                for addr in to {
                    if let Some(peer) = peers.get_mut(&amp;addr) {
                        let msg = format!(&quot;from {}: {}\n&quot;, from, msg);
                        peer.send(msg).await?
                    }
                }
            }
            Event::NewPeer { name, stream} =&gt; {
                match peers.entry(name) {
                    Entry::Occupied(..) =&gt; (),
                    Entry::Vacant(entry) =&gt; {
                        let (client_sender, client_receiver) = mpsc::unbounded();
                        entry.insert(client_sender); // 4
                        spawn_and_log_error(connection_writer_loop(client_receiver, stream)); // 5
                    }
                }
            }
        }
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>Inside the <code>accept_loop</code>, we create the broker's channel and <code>task</code>.</li>
<li>Inside <code>connection_loop</code>, we need to wrap <code>TcpStream</code> into an <code>Arc</code>, to be able to share it with the <code>connection_writer_loop</code>.</li>
<li>On login, we notify the broker.
Note that we <code>.unwrap</code> on send: broker should outlive all the clients and if that's not the case the broker probably panicked, so we can escalate the panic as well.</li>
<li>Similarly, we forward parsed messages to the broker, assuming that it is alive.</li>
</ol>
<h2><a class="header" href="#clean-shutdown" id="clean-shutdown">Clean Shutdown</a></h2>
<p>One of the problems of the current implementation is that it doesn't handle graceful shutdown.
If we break from the accept loop for some reason, all in-flight tasks are just dropped on the floor.
A more correct shutdown sequence would be:</p>
<ol>
<li>Stop accepting new clients</li>
<li>Deliver all pending messages</li>
<li>Exit the process</li>
</ol>
<p>A clean shutdown in a channel based architecture is easy, although it can appear a magic trick at first.
In Rust, receiver side of a channel is closed as soon as all senders are dropped.
That is, as soon as producers exit and drop their senders, the rest of the system shuts down naturally.
In <code>async_std</code> this translates to two rules:</p>
<ol>
<li>Make sure that channels form an acyclic graph.</li>
<li>Take care to wait, in the correct order, until intermediate layers of the system process pending messages.</li>
</ol>
<p>In <code>a-chat</code>, we already have an unidirectional flow of messages: <code>reader -&gt; broker -&gt; writer</code>.
However, we never wait for broker and writers, which might cause some messages to get dropped.
Let's add waiting to the server:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::{
</span><span class="boring">    io::{self, BufReader},
</span><span class="boring">    net::{TcpListener, TcpStream, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">use futures::channel::mpsc;
</span><span class="boring">use futures::sink::SinkExt;
</span><span class="boring">use std::{
</span><span class="boring">    collections::hash_map::{HashMap, Entry},
</span><span class="boring">    sync::Arc,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
</span><span class="boring">type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;
</span><span class="boring">
</span><span class="boring">fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
</span><span class="boring">where
</span><span class="boring">    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
</span><span class="boring">{
</span><span class="boring">    task::spawn(async move {
</span><span class="boring">        if let Err(e) = fut.await {
</span><span class="boring">            eprintln!(&quot;{}&quot;, e)
</span><span class="boring">        }
</span><span class="boring">    })
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">
</span><span class="boring">async fn connection_loop(mut broker: Sender&lt;Event&gt;, stream: TcpStream) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let stream = Arc::new(stream); // 2
</span><span class="boring">    let reader = BufReader::new(&amp;*stream);
</span><span class="boring">    let mut lines = reader.lines();
</span><span class="boring">
</span><span class="boring">    let name = match lines.next().await {
</span><span class="boring">        None =&gt; Err(&quot;peer disconnected immediately&quot;)?,
</span><span class="boring">        Some(line) =&gt; line?,
</span><span class="boring">    };
</span><span class="boring">    broker.send(Event::NewPeer { name: name.clone(), stream: Arc::clone(&amp;stream) }).await // 3
</span><span class="boring">        .unwrap();
</span><span class="boring">
</span><span class="boring">    while let Some(line) = lines.next().await {
</span><span class="boring">        let line = line?;
</span><span class="boring">        let (dest, msg) = match line.find(':') {
</span><span class="boring">            None =&gt; continue,
</span><span class="boring">            Some(idx) =&gt; (&amp;line[..idx], line[idx + 1 ..].trim()),
</span><span class="boring">        };
</span><span class="boring">        let dest: Vec&lt;String&gt; = dest.split(',').map(|name| name.trim().to_string()).collect();
</span><span class="boring">        let msg: String = msg.trim().to_string();
</span><span class="boring">
</span><span class="boring">        broker.send(Event::Message { // 4
</span><span class="boring">            from: name.clone(),
</span><span class="boring">            to: dest,
</span><span class="boring">            msg,
</span><span class="boring">        }).await.unwrap();
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">async fn connection_writer_loop(
</span><span class="boring">    mut messages: Receiver&lt;String&gt;,
</span><span class="boring">    stream: Arc&lt;TcpStream&gt;,
</span><span class="boring">) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let mut stream = &amp;*stream;
</span><span class="boring">    while let Some(msg) = messages.next().await {
</span><span class="boring">        stream.write_all(msg.as_bytes()).await?;
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">enum Event {
</span><span class="boring">    NewPeer {
</span><span class="boring">        name: String,
</span><span class="boring">        stream: Arc&lt;TcpStream&gt;,
</span><span class="boring">    },
</span><span class="boring">    Message {
</span><span class="boring">        from: String,
</span><span class="boring">        to: Vec&lt;String&gt;,
</span><span class="boring">        msg: String,
</span><span class="boring">    },
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">async fn broker_loop(mut events: Receiver&lt;Event&gt;) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let mut peers: HashMap&lt;String, Sender&lt;String&gt;&gt; = HashMap::new();
</span><span class="boring">
</span><span class="boring">    while let Some(event) = events.next().await {
</span><span class="boring">        match event {
</span><span class="boring">            Event::Message { from, to, msg } =&gt; {
</span><span class="boring">                for addr in to {
</span><span class="boring">                    if let Some(peer) = peers.get_mut(&amp;addr) {
</span><span class="boring">                        let msg = format!(&quot;from {}: {}\n&quot;, from, msg);
</span><span class="boring">                        peer.send(msg).await?
</span><span class="boring">                    }
</span><span class="boring">                }
</span><span class="boring">            }
</span><span class="boring">            Event::NewPeer { name, stream} =&gt; {
</span><span class="boring">                match peers.entry(name) {
</span><span class="boring">                    Entry::Occupied(..) =&gt; (),
</span><span class="boring">                    Entry::Vacant(entry) =&gt; {
</span><span class="boring">                        let (client_sender, client_receiver) = mpsc::unbounded();
</span><span class="boring">                        entry.insert(client_sender); // 4
</span><span class="boring">                        spawn_and_log_error(connection_writer_loop(client_receiver, stream)); // 5
</span><span class="boring">                    }
</span><span class="boring">                }
</span><span class="boring">            }
</span><span class="boring">        }
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let listener = TcpListener::bind(addr).await?;

    let (broker_sender, broker_receiver) = mpsc::unbounded();
    let broker_handle = task::spawn(broker_loop(broker_receiver));
    let mut incoming = listener.incoming();
    while let Some(stream) = incoming.next().await {
        let stream = stream?;
        println!(&quot;Accepting from: {}&quot;, stream.peer_addr()?);
        spawn_and_log_error(connection_loop(broker_sender.clone(), stream));
    }
    drop(broker_sender); // 1
    broker_handle.await?; // 5
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>And to the broker:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::{
</span><span class="boring">    io::{self, BufReader},
</span><span class="boring">    net::{TcpListener, TcpStream, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">    task,
</span><span class="boring">};
</span><span class="boring">use futures::channel::mpsc;
</span><span class="boring">use futures::sink::SinkExt;
</span><span class="boring">use std::{
</span><span class="boring">    collections::hash_map::{HashMap, Entry},
</span><span class="boring">    sync::Arc,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
</span><span class="boring">type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;
</span><span class="boring">
</span><span class="boring">async fn connection_writer_loop(
</span><span class="boring">    mut messages: Receiver&lt;String&gt;,
</span><span class="boring">    stream: Arc&lt;TcpStream&gt;,
</span><span class="boring">) -&gt; Result&lt;()&gt; {
</span><span class="boring">    let mut stream = &amp;*stream;
</span><span class="boring">    while let Some(msg) = messages.next().await {
</span><span class="boring">        stream.write_all(msg.as_bytes()).await?;
</span><span class="boring">    }
</span><span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
</span><span class="boring">where
</span><span class="boring">    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
</span><span class="boring">{
</span><span class="boring">    task::spawn(async move {
</span><span class="boring">        if let Err(e) = fut.await {
</span><span class="boring">            eprintln!(&quot;{}&quot;, e)
</span><span class="boring">        }
</span><span class="boring">    })
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">enum Event {
</span><span class="boring">    NewPeer {
</span><span class="boring">        name: String,
</span><span class="boring">        stream: Arc&lt;TcpStream&gt;,
</span><span class="boring">    },
</span><span class="boring">    Message {
</span><span class="boring">        from: String,
</span><span class="boring">        to: Vec&lt;String&gt;,
</span><span class="boring">        msg: String,
</span><span class="boring">    },
</span><span class="boring">}
</span><span class="boring">
</span>async fn broker_loop(mut events: Receiver&lt;Event&gt;) -&gt; Result&lt;()&gt; {
    let mut writers = Vec::new();
    let mut peers: HashMap&lt;String, Sender&lt;String&gt;&gt; = HashMap::new();
    while let Some(event) = events.next().await { // 2
        match event {
            Event::Message { from, to, msg } =&gt; {
                for addr in to {
                    if let Some(peer) = peers.get_mut(&amp;addr) {
                        let msg = format!(&quot;from {}: {}\n&quot;, from, msg);
                        peer.send(msg).await?
                    }
                }
            }
            Event::NewPeer { name, stream} =&gt; {
                match peers.entry(name) {
                    Entry::Occupied(..) =&gt; (),
                    Entry::Vacant(entry) =&gt; {
                        let (client_sender, client_receiver) = mpsc::unbounded();
                        entry.insert(client_sender);
                        let handle = spawn_and_log_error(connection_writer_loop(client_receiver, stream));
                        writers.push(handle); // 4
                    }
                }
            }
        }
    }
    drop(peers); // 3
    for writer in writers { // 4
        writer.await;
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>Notice what happens with all of the channels once we exit the accept loop:</p>
<ol>
<li>First, we drop the main broker's sender.
That way when the readers are done, there's no sender for the broker's channel, and the chanel closes.</li>
<li>Next, the broker exits <code>while let Some(event) = events.next().await</code> loop.</li>
<li>It's crucial that, at this stage, we drop the <code>peers</code> map.
This drops writer's senders.</li>
<li>Now we can join all of the writers.</li>
<li>Finally, we join the broker, which also guarantees that all the writes have terminated.</li>
</ol>
<h2><a class="header" href="#handling-disconnections" id="handling-disconnections">Handling Disconnections</a></h2>
<p>Currently, we only ever <em>add</em> new peers to the map.
This is clearly wrong: if a peer closes connection to the chat, we should not try to send any more messages to it.</p>
<p>One subtlety with handling disconnection is that we can detect it either in the reader's task, or in the writer's task.
The most obvious solution here is to just remove the peer from the <code>peers</code> map in both cases, but this would be wrong.
If <em>both</em> read and write fail, we'll remove the peer twice, but it can be the case that the peer reconnected between the two failures!
To fix this, we will only remove the peer when the write side finishes.
If the read side finishes we will notify the write side that it should stop as well.
That is, we need to add an ability to signal shutdown for the writer task.</p>
<p>One way to approach this is a <code>shutdown: Receiver&lt;()&gt;</code> channel.
There's a more minimal solution however, which makes clever use of RAII.
Closing a channel is a synchronization event, so we don't need to send a shutdown message, we can just drop the sender.
This way, we statically guarantee that we issue shutdown exactly once, even if we early return via <code>?</code> or panic.</p>
<p>First, let's add a shutdown channel to the <code>connection_loop</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::net::TcpStream;
</span><span class="boring">use futures::channel::mpsc;
</span><span class="boring">use futures::sink::SinkExt;
</span><span class="boring">use std::sync::Arc;
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
</span><span class="boring">type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;
</span><span class="boring">
</span>#[derive(Debug)]
enum Void {} // 1

#[derive(Debug)]
enum Event {
    NewPeer {
        name: String,
        stream: Arc&lt;TcpStream&gt;,
        shutdown: Receiver&lt;Void&gt;, // 2
    },
    Message {
        from: String,
        to: Vec&lt;String&gt;,
        msg: String,
    },
}

async fn connection_loop(mut broker: Sender&lt;Event&gt;, stream: Arc&lt;TcpStream&gt;) -&gt; Result&lt;()&gt; {
    // ...
<span class="boring">  let name: String = unimplemented!();
</span>    let (_shutdown_sender, shutdown_receiver) = mpsc::unbounded::&lt;Void&gt;(); // 3
    broker.send(Event::NewPeer {
        name: name.clone(),
        stream: Arc::clone(&amp;stream),
        shutdown: shutdown_receiver,
    }).await.unwrap();
    // ...
<span class="boring">  unimplemented!()
</span>}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>To enforce that no messages are sent along the shutdown channel, we use an uninhabited type.</li>
<li>We pass the shutdown channel to the writer task.</li>
<li>In the reader, we create a <code>_shutdown_sender</code> whose only purpose is to get dropped.</li>
</ol>
<p>In the <code>connection_writer_loop</code>, we now need to choose between shutdown and message channels.
We use the <code>select</code> macro for this purpose:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span><span class="boring">use async_std::{net::TcpStream, prelude::*};
</span><span class="boring">use futures::channel::mpsc;
</span>use futures::{select, FutureExt};
<span class="boring">use std::sync::Arc;
</span><span class="boring">type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
</span><span class="boring">#[derive(Debug)]
</span><span class="boring">enum Void {} // 1
</span>
async fn connection_writer_loop(
    messages: &amp;mut Receiver&lt;String&gt;,
    stream: Arc&lt;TcpStream&gt;,
    shutdown: Receiver&lt;Void&gt;, // 1
) -&gt; Result&lt;()&gt; {
    let mut stream = &amp;*stream;
    let mut messages = messages.fuse();
    let mut shutdown = shutdown.fuse();
    loop { // 2
        select! {
            msg = messages.next().fuse() =&gt; match msg {
                Some(msg) =&gt; stream.write_all(msg.as_bytes()).await?,
                None =&gt; break,
            },
            void = shutdown.next().fuse() =&gt; match void {
                Some(void) =&gt; match void {}, // 3
                None =&gt; break,
            }
        }
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>We add shutdown channel as an argument.</li>
<li>Because of <code>select</code>, we can't use a <code>while let</code> loop, so we desugar it further into a <code>loop</code>.</li>
<li>In the shutdown case we use <code>match void {}</code> as a statically-checked <code>unreachable!()</code>.</li>
</ol>
<p>Another problem is that between the moment we detect disconnection in <code>connection_writer_loop</code> and the moment when we actually remove the peer from the <code>peers</code> map, new messages might be pushed into the peer's channel.
To not lose these messages completely, we'll return the messages channel back to the broker.
This also allows us to establish a useful invariant that the message channel strictly outlives the peer in the <code>peers</code> map, and makes the broker itself infallible.</p>
<h2><a class="header" href="#final-code" id="final-code">Final Code</a></h2>
<p>The final code looks like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span>use async_std::{
    io::BufReader,
    net::{TcpListener, TcpStream, ToSocketAddrs},
    prelude::*,
    task,
};
use futures::channel::mpsc;
use futures::sink::SinkExt;
use futures::{select, FutureExt};
use std::{
    collections::hash_map::{Entry, HashMap},
    future::Future,
    sync::Arc,
};

type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
type Sender&lt;T&gt; = mpsc::UnboundedSender&lt;T&gt;;
type Receiver&lt;T&gt; = mpsc::UnboundedReceiver&lt;T&gt;;

#[derive(Debug)]
enum Void {}

// main
fn run() -&gt; Result&lt;()&gt; {
    task::block_on(accept_loop(&quot;127.0.0.1:8080&quot;))
}

async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let listener = TcpListener::bind(addr).await?;
    let (broker_sender, broker_receiver) = mpsc::unbounded();
    let broker_handle = task::spawn(broker_loop(broker_receiver));
    let mut incoming = listener.incoming();
    while let Some(stream) = incoming.next().await {
        let stream = stream?;
        println!(&quot;Accepting from: {}&quot;, stream.peer_addr()?);
        spawn_and_log_error(connection_loop(broker_sender.clone(), stream));
    }
    drop(broker_sender);
    broker_handle.await;
    Ok(())
}

async fn connection_loop(mut broker: Sender&lt;Event&gt;, stream: TcpStream) -&gt; Result&lt;()&gt; {
    let stream = Arc::new(stream);
    let reader = BufReader::new(&amp;*stream);
    let mut lines = reader.lines();

    let name = match lines.next().await {
        None =&gt; Err(&quot;peer disconnected immediately&quot;)?,
        Some(line) =&gt; line?,
    };
    let (_shutdown_sender, shutdown_receiver) = mpsc::unbounded::&lt;Void&gt;();
    broker.send(Event::NewPeer {
        name: name.clone(),
        stream: Arc::clone(&amp;stream),
        shutdown: shutdown_receiver,
    }).await.unwrap();

    while let Some(line) = lines.next().await {
        let line = line?;
        let (dest, msg) = match line.find(':') {
            None =&gt; continue,
            Some(idx) =&gt; (&amp;line[..idx], line[idx + 1 ..].trim()),
        };
        let dest: Vec&lt;String&gt; = dest.split(',').map(|name| name.trim().to_string()).collect();
        let msg: String = msg.trim().to_string();

        broker.send(Event::Message {
            from: name.clone(),
            to: dest,
            msg,
        }).await.unwrap();
    }

    Ok(())
}

async fn connection_writer_loop(
    messages: &amp;mut Receiver&lt;String&gt;,
    stream: Arc&lt;TcpStream&gt;,
    shutdown: Receiver&lt;Void&gt;,
) -&gt; Result&lt;()&gt; {
    let mut stream = &amp;*stream;
    let mut messages = messages.fuse();
    let mut shutdown = shutdown.fuse();
    loop {
        select! {
            msg = messages.next().fuse() =&gt; match msg {
                Some(msg) =&gt; stream.write_all(msg.as_bytes()).await?,
                None =&gt; break,
            },
            void = shutdown.next().fuse() =&gt; match void {
                Some(void) =&gt; match void {},
                None =&gt; break,
            }
        }
    }
    Ok(())
}

#[derive(Debug)]
enum Event {
    NewPeer {
        name: String,
        stream: Arc&lt;TcpStream&gt;,
        shutdown: Receiver&lt;Void&gt;,
    },
    Message {
        from: String,
        to: Vec&lt;String&gt;,
        msg: String,
    },
}

async fn broker_loop(events: Receiver&lt;Event&gt;) {
    let (disconnect_sender, mut disconnect_receiver) = // 1
        mpsc::unbounded::&lt;(String, Receiver&lt;String&gt;)&gt;();
    let mut peers: HashMap&lt;String, Sender&lt;String&gt;&gt; = HashMap::new();
    let mut events = events.fuse();
    loop {
        let event = select! {
            event = events.next().fuse() =&gt; match event {
                None =&gt; break, // 2
                Some(event) =&gt; event,
            },
            disconnect = disconnect_receiver.next().fuse() =&gt; {
                let (name, _pending_messages) = disconnect.unwrap(); // 3
                assert!(peers.remove(&amp;name).is_some());
                continue;
            },
        };
        match event {
            Event::Message { from, to, msg } =&gt; {
                for addr in to {
                    if let Some(peer) = peers.get_mut(&amp;addr) {
                        let msg = format!(&quot;from {}: {}\n&quot;, from, msg);
                        peer.send(msg).await
                            .unwrap() // 6
                    }
                }
            }
            Event::NewPeer { name, stream, shutdown } =&gt; {
                match peers.entry(name.clone()) {
                    Entry::Occupied(..) =&gt; (),
                    Entry::Vacant(entry) =&gt; {
                        let (client_sender, mut client_receiver) = mpsc::unbounded();
                        entry.insert(client_sender);
                        let mut disconnect_sender = disconnect_sender.clone();
                        spawn_and_log_error(async move {
                            let res = connection_writer_loop(&amp;mut client_receiver, stream, shutdown).await;
                            disconnect_sender.send((name, client_receiver)).await // 4
                                .unwrap();
                            res
                        });
                    }
                }
            }
        }
    }
    drop(peers); // 5
    drop(disconnect_sender); // 6
    while let Some((_name, _pending_messages)) = disconnect_receiver.next().await {
    }
}

fn spawn_and_log_error&lt;F&gt;(fut: F) -&gt; task::JoinHandle&lt;()&gt;
where
    F: Future&lt;Output = Result&lt;()&gt;&gt; + Send + 'static,
{
    task::spawn(async move {
        if let Err(e) = fut.await {
            eprintln!(&quot;{}&quot;, e)
        }
    })
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>In the broker, we create a channel to reap disconnected peers and their undelivered messages.</li>
<li>The broker's main loop exits when the input events channel is exhausted (that is, when all readers exit).</li>
<li>Because broker itself holds a <code>disconnect_sender</code>, we know that the disconnections channel can't be fully drained in the main loop.</li>
<li>We send peer's name and pending messages to the disconnections channel in both the happy and the not-so-happy path.
Again, we can safely unwrap because the broker outlives writers.</li>
<li>We drop <code>peers</code> map to close writers' messages channel and shut down the writers for sure.
It is not strictly necessary in the current setup, where the broker waits for readers' shutdown anyway.
However, if we add a server-initiated shutdown (for example, kbd:[ctrl+c] handling), this will be a way for the broker to shutdown the writers.</li>
<li>Finally, we close and drain the disconnections channel.</li>
</ol>
<h2><a class="header" href="#implementing-a-client" id="implementing-a-client">Implementing a client</a></h2>
<p>Since the protocol is line-based, implementing a client for the chat is straightforward:</p>
<ul>
<li>Lines read from stdin should be sent over the socket.</li>
<li>Lines read from the socket should be echoed to stdout.</li>
</ul>
<p>Although async does not significantly affect client performance (as unlike the server, the client interacts solely with one user and only needs limited concurrency), async is still useful for managing concurrency!</p>
<p>The client has to read from stdin and the socket <em>simultaneously</em>.
Programming this with threads is cumbersome, especially when implementing a clean shutdown.
With async, the <code>select!</code> macro is all that is needed.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate futures;
</span>use async_std::{
    io::{stdin, BufReader},
    net::{TcpStream, ToSocketAddrs},
    prelude::*,
    task,
};
use futures::{select, FutureExt};

type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;

// main
fn run() -&gt; Result&lt;()&gt; {
    task::block_on(try_run(&quot;127.0.0.1:8080&quot;))
}

async fn try_run(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let stream = TcpStream::connect(addr).await?;
    let (reader, mut writer) = (&amp;stream, &amp;stream); // 1
    let mut lines_from_server = BufReader::new(reader).lines().fuse(); // 2
    let mut lines_from_stdin = BufReader::new(stdin()).lines().fuse(); // 2
    loop {
        select! { // 3
            line = lines_from_server.next().fuse() =&gt; match line {
                Some(line) =&gt; {
                    let line = line?;
                    println!(&quot;{}&quot;, line);
                },
                None =&gt; break,
            },
            line = lines_from_stdin.next().fuse() =&gt; match line {
                Some(line) =&gt; {
                    let line = line?;
                    writer.write_all(line.as_bytes()).await?;
                    writer.write_all(b&quot;\n&quot;).await?;
                }
                None =&gt; break,
            }
        }
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>Here we split <code>TcpStream</code> into read and write halves: there's <code>impl AsyncRead for &amp;'_ TcpStream</code>, just like the one in std.</li>
<li>We create a stream of lines for both the socket and stdin.</li>
<li>In the main select loop, we print the lines we receive from the server and send the lines we read from the console.</li>
</ol>
<h1><a class="header" href="#patterns" id="patterns">Patterns</a></h1>
<p>This section documents small, useful patterns.</p>
<p>It is intended to be read at a glance, allowing you to get back when you have a problem.</p>
<h1><a class="header" href="#small-patterns" id="small-patterns">Small Patterns</a></h1>
<p>A collection of small, useful patterns.</p>
<h2><a class="header" href="#splitting-streams" id="splitting-streams">Splitting streams</a></h2>
<p><code>async-std</code> doesn't provide a <code>split()</code> method on <code>io</code> handles. Instead, splitting a stream into a read and write half can be done like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span>use async_std::{io, net::TcpStream};
async fn echo(stream: TcpStream) {
    let (reader, writer) = &amp;mut (&amp;stream, &amp;stream);
    io::copy(reader, writer).await;
}
<span class="boring">}
</span></code></pre></pre>
<h1><a class="header" href="#production-ready-accept-loop" id="production-ready-accept-loop">Production-Ready Accept Loop</a></h1>
<p>A production-ready accept loop needs the following things:</p>
<ol>
<li>Handling errors</li>
<li>Limiting the number of simultanteous connections to avoid deny-of-service
(DoS) attacks</li>
</ol>
<h2><a class="header" href="#handling-errors" id="handling-errors">Handling errors</a></h2>
<p>There are two kinds of errors in an accept loop:</p>
<ol>
<li>Per-connection errors. The system uses them to notify that there was a
connection in the queue and it's dropped by the peer. Subsequent connections
can be already queued so next connection must be accepted immediately.</li>
<li>Resource shortages. When these are encountered it doesn't make sense to
accept the next socket immediately. But the listener stays active, so you server
should try to accept socket later.</li>
</ol>
<p>Here is the example of a per-connection error (printed in normal and debug mode):</p>
<pre><code>Error: Connection reset by peer (os error 104)
Error: Os { code: 104, kind: ConnectionReset, message: &quot;Connection reset by peer&quot; }
</code></pre>
<p>And the following is the most common example of a resource shortage error:</p>
<pre><code>Error: Too many open files (os error 24)
Error: Os { code: 24, kind: Other, message: &quot;Too many open files&quot; }
</code></pre>
<h3><a class="header" href="#testing-application" id="testing-application">Testing Application</a></h3>
<p>To test your application for these errors try the following (this works
on unixes only).</p>
<p>Lower limits and start the application:</p>
<pre><code>$ ulimit -n 100
$ cargo run --example your_app
   Compiling your_app v0.1.0 (/work)
    Finished dev [unoptimized + debuginfo] target(s) in 5.47s
     Running `target/debug/examples/your_app`
Server is listening on: http://127.0.0.1:1234
</code></pre>
<p>Then in another console run the <a href="https://github.com/wg/wrk"><code>wrk</code></a> benchmark tool:</p>
<pre><code>$ wrk -c 1000 http://127.0.0.1:1234
Running 10s test @ http://localhost:8080/
  2 threads and 1000 connections
$ telnet localhost 1234
Trying ::1...
Connected to localhost.
</code></pre>
<p>Important is to check the following things:</p>
<ol>
<li>The application doesn't crash on error (but may log errors, see below)</li>
<li>It's possible to connect to the application again once load is stopped
(few seconds after <code>wrk</code>). This is what <code>telnet</code> does in example above,
make sure it prints <code>Connected to &lt;hostname&gt;</code>.</li>
<li>The <code>Too many open files</code> error is logged in the appropriate log. This
requires to set &quot;maximum number of simultaneous connections&quot; parameter (see
below) of your application to a value greater then <code>100</code> for this example.</li>
<li>Check CPU usage of the app while doing a test. It should not occupy 100%
of a single CPU core (it's unlikely that you can exhaust CPU by 1000
connections in Rust, so this means error handling is not right).</li>
</ol>
<h4><a class="header" href="#testing-non-http-applications" id="testing-non-http-applications">Testing non-HTTP applications</a></h4>
<p>If it's possible, use the appropriate benchmark tool and set the appropriate
number of connections. For example <code>redis-benchmark</code> has a <code>-c</code> parameter for
that, if you implement redis protocol.</p>
<p>Alternatively, can still use <code>wrk</code>, just make sure that connection is not
immediately closed. If it is, put a temporary timeout before handing
the connection to the protocol handler, like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span><span class="boring">async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
</span><span class="boring">   let listener = TcpListener::bind(addr).await?;
</span><span class="boring">   let mut incoming = listener.incoming();
</span>while let Some(stream) = incoming.next().await {
    task::spawn(async {
        task::sleep(Duration::from_secs(10)).await; // 1
        connection_loop(stream).await;
    });
}
<span class="boring">    Ok(())
</span><span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<ol>
<li>Make sure the sleep coroutine is inside the spawned task, not in the loop.</li>
</ol>
<h3><a class="header" href="#handling-errors-manually" id="handling-errors-manually">Handling Errors Manually</a></h3>
<p>Here is how basic accept loop could look like:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    let listener = TcpListener::bind(addr).await?;
    let mut incoming = listener.incoming();
    while let Some(result) = incoming.next().await {
        let stream = match result {
            Err(ref e) if is_connection_error(e) =&gt; continue, // 1
            Err(e) =&gt; {
                eprintln!(&quot;Error: {}. Pausing for 500ms.&quot;, e); // 3
                task::sleep(Duration::from_millis(500)).await; // 2
                continue;
            }
            Ok(s) =&gt; s,
        };
        // body
    }
    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>Ignore per-connection errors.</li>
<li>Sleep and continue on resource shortage.</li>
<li>It's important to log the message, because these errors commonly mean the
misconfiguration of the system and are helpful for operations people running
the application.</li>
</ol>
<p>Be sure to <a href="patterns/accept-loop.html#testing-application">test your application</a>.</p>
<h3><a class="header" href="#external-crates" id="external-crates">External Crates</a></h3>
<p>The crate <a href="https://crates.io/crates/async-listen/"><code>async-listen</code></a> has a helper to achieve this task:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate async_listen;
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span>use async_listen::{ListenExt, error_hint};

async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {

    let listener = TcpListener::bind(addr).await?;
    let mut incoming = listener
        .incoming()
        .log_warnings(log_accept_error) // 1
        .handle_errors(Duration::from_millis(500));
    while let Some(socket) = incoming.next().await { // 2
        // body
    }
    Ok(())
}

fn log_accept_error(e: &amp;io::Error) {
    eprintln!(&quot;Error: {}. Listener paused for 0.5s. {}&quot;, e, error_hint(e)) // 3
}
<span class="boring">}
</span></code></pre></pre>
<ol>
<li>Logs resource shortages (<code>async-listen</code> calls them warnings). If you use
<code>log</code> crate or any other in your app this should go to the log.</li>
<li>Stream yields sockets without <code>Result</code> wrapper after <code>handle_errors</code> because
all errors are already handled.</li>
<li>Together with the error we print a hint, which explains some errors for end
users. For example, it recommends increasing open file limit and gives
a link.</li>
</ol>
<p>Be sure to <a href="patterns/accept-loop.html#testing-application">test your application</a>.</p>
<h2><a class="header" href="#connections-limit" id="connections-limit">Connections Limit</a></h2>
<p>Even if you've applied everything described in
<a href="patterns/accept-loop.html#handling-errors">Handling Errors</a> section, there is still a problem.</p>
<p>Let's imagine you have a server that needs to open a file to process
client request. At some point, you might encounter the following situation:</p>
<ol>
<li>There are as many client connection as max file descriptors allowed for
the application.</li>
<li>Listener gets <code>Too many open files</code> error so it sleeps.</li>
<li>Some client sends a request via the previously open connection.</li>
<li>Opening a file to serve request fails, because of the same
<code>Too many open files</code> error, until some other client drops a connection.</li>
</ol>
<p>There are many more possible situations, this is just a small illustation that
limiting number of connections is very useful. Generally, it's one of the ways
to control resources used by a server and avoiding some kinds of deny of
service (DoS) attacks.</p>
<h3><a class="header" href="#async-listen-crate" id="async-listen-crate"><code>async-listen</code> crate</a></h3>
<p>Limiting maximum number of simultaneous connections with <a href="https://crates.io/crates/async-listen/"><code>async-listen</code></a>
looks like the following:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate async_std;
</span><span class="boring">extern crate async_listen;
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use async_std::{
</span><span class="boring">    net::{TcpListener, TcpStream, ToSocketAddrs},
</span><span class="boring">    prelude::*,
</span><span class="boring">};
</span><span class="boring">
</span><span class="boring">type Result&lt;T&gt; = std::result::Result&lt;T, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
</span><span class="boring">
</span>use async_listen::{ListenExt, Token, error_hint};

async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {

    let listener = TcpListener::bind(addr).await?;
    let mut incoming = listener
        .incoming()
        .log_warnings(log_accept_error)
        .handle_errors(Duration::from_millis(500)) // 1
        .backpressure(100);
    while let Some((token, socket)) = incoming.next().await { // 2
         task::spawn(async move {
             connection_loop(&amp;token, stream).await; // 3
         });
    }
    Ok(())
}
async fn connection_loop(_token: &amp;Token, stream: TcpStream) { // 4
    // ...
}
<span class="boring">fn log_accept_error(e: &amp;io::Error) {
</span><span class="boring">    eprintln!(&quot;Error: {}. Listener paused for 0.5s. {}&quot;, e, error_hint(e));
</span><span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<ol>
<li>We need to handle errors first, because <a href="https://docs.rs/async-listen/0.1.2/async_listen/trait.ListenExt.html#method.backpressure"><code>backpressure</code></a> helper expects
stream of <code>TcpStream</code> rather than <code>Result</code>.</li>
<li>The token yielded by a new stream is what is counted by backpressure helper.
I.e. if you drop a token, new connection can be established.</li>
<li>We give the connection loop a reference to token to bind token's lifetime to
the lifetime of the connection.</li>
<li>The token itsellf in the function can be ignored, hence <code>_token</code></li>
</ol>
<p>Be sure to <a href="patterns/accept-loop.html#testing-application">test this behavior</a>.</p>
<h1><a class="header" href="#security" id="security">Security</a></h1>
<p>Writing a highly perfomant async core library is a task involving some instances of unsafe code.</p>
<p>We take great care in vetting all unsafe code included in <code>async-std</code> and do follow generally accepted practices.</p>
<p>In the case that you find a security-related bug in our library, please get in touch with our <a href="security//security/policy">security contact</a>.</p>
<p>Patches improving the resilience of the library or the testing setup are happily accepted on our <a href="https://github.com/async-rs">github org</a>.</p>
<h1><a class="header" href="#policy" id="policy">Policy</a></h1>
<p>Safety is one of the core principles of what we do, and to that end, we would like to ensure that async-std has a secure implementation. Thank you for taking the time to responsibly disclose any issues you find.</p>
<p>All security bugs in async-std distribution should be reported by email to florian.gilcher@ferrous-systems.com. This list is delivered to a small security team. Your email will be acknowledged within 24 hours, and you’ll receive a more detailed response to your email within 48 hours indicating the next steps in handling your report. If you would like, you can encrypt your report using our public key. This key is also On MIT’s keyserver and reproduced below.</p>
<p>Be sure to use a descriptive subject line to avoid having your report be missed. After the initial reply to your report, the security team will endeavor to keep you informed of the progress being made towards a fix and full announcement. As recommended by <a href="https://en.wikipedia.org/wiki/RFPolicy">RFPolicy</a>, these updates will be sent at least every five days. In reality, this is more likely to be every 24-48 hours.</p>
<p>If you have not received a reply to your email within 48 hours, or have not heard from the security team for the past five days, there are a few steps you can take (in order):</p>
<ul>
<li>Post on our Community forums</li>
</ul>
<p>Please note that the discussion forums are public areas. When escalating in these venues, please do not discuss your issue. Simply say that you’re trying to get a hold of someone from the security team.</p>
<h2><a class="header" href="#disclosure-policy" id="disclosure-policy">Disclosure policy</a></h2>
<p>The async-std project has a 5 step disclosure process.</p>
<ul>
<li>The security report is received and is assigned a primary handler. This person will coordinate the fix and release process.</li>
<li>The problem is confirmed and a list of all affected versions is determined.</li>
<li>Code is audited to find any potential similar problems.</li>
<li>Fixes are prepared for all releases which are still under maintenance. These fixes are not committed to the public repository but rather held locally pending the announcement.</li>
<li>On the embargo date, the changes are pushed to the public repository and new builds are deployed to crates.io. Within 6 hours, a copy of the advisory will be published on the the async.rs blog.</li>
</ul>
<p>This process can take some time, especially when coordination is required with maintainers of other projects. Every effort will be made to handle the bug in as timely a manner as possible, however it's important that we follow the release process above to ensure that the disclosure is handled in a consistent manner.</p>
<h2><a class="header" href="#credits-1" id="credits-1">Credits</a></h2>
<p>This policy is adapted from the <a href="https://www.rust-lang.org/policies/security">Rust project</a> security policy.</p>
<h2><a class="header" href="#pgp-key" id="pgp-key">PGP Key</a></h2>
<pre><code class="language-text">-----BEGIN PGP PUBLIC KEY BLOCK-----

mQENBF1Wu/ABCADJaGt4HwSlqKB9BGHWYKZj/6mTMbmc29vsEOcCSQKo6myCf9zc
sasWAttep4FAUDX+MJhVbBTSq9M1YVxp33Qh5AF0t9SnJZnbI+BZuGawcHDL01xE
bE+8bcA2+szeTTUZCeWwsaoTd/2qmQKvpUCBQp7uBs/ITO/I2q7+xCGXaOHZwUKc
H8SUBLd35nYFtjXAeejoZVkqG2qEjrc9bkZAwxFXi7Fw94QdkNLaCjNfKxZON/qP
A3WOpyWPr3ERk5C5prjEAvrW8kdqpTRjdmzQjsr8UEXb5GGEOo93N4OLZVQ2mXt9
dfn++GOnOk7sTxvfiDH8Ru5o4zCtKgO+r5/LABEBAAG0UkZsb3JpYW4gR2lsY2hl
ciAoU2VjdXJpdHkgY29udGFjdCBhc3luYy1zdGQpIDxmbG9yaWFuLmdpbGNoZXJA
ZmVycm91cy1zeXN0ZW1zLmNvbT6JATgEEwECACIFAl1Wu/ACGwMGCwkIBwMCBhUI
AgkKCwQWAgMBAh4BAheAAAoJEACXY97PwLtSc0AH/18yvrElVOkG0ADWX7l+JKHH
nMQtYj0Auop8d6TuKBbpwtYhwELrQoITDMV7f2XEnchNsvYxAyBZhIISmXeJboE1
KzZD1O+4QPXRcXhj+QNsKQ680mrgZXgAI2Y4ptIW9Vyw3jiHu/ZVopvDAt4li+up
3fRJGPAvGu+tclpJmA+Xam23cDj89M7/wHHgKIyT59WgFwyCgibL+NHKwg2Unzou
9uyZQnq6hf62sQTWEZIAr9BQpKmluplNIJHDeECWzZoE9ucE2ZXsq5pq9qojsAMK
yRdaFdpBcD/AxtrTKFeXGS7X7LqaljY/IFBEdJOqVNWpqSLjGWqjSLIEsc1AB0K5
AQ0EXVa78AEIAJMxBOEEW+2c3CcjFuUfcRsoBsFH3Vk+GwCbjIpNHq/eAvS1yy2L
u10U5CcT5Xb6be3AeCYv00ZHVbEi6VwoauVCSX8qDjhVzQxvNLgQ1SduobjyF6t8
3M/wTija6NvMKszyw1l2oHepxSMLej1m49DyCDFNiZm5rjQcYnFT4J71syxViqHF
v2fWCheTrHP3wfBAt5zyDet7IZd/EhYAK6xXEwr9nBPjfbaVexm2B8K6hOPNj0Bp
OKm4rcOj7JYlcxrwhMvNnwEue7MqH1oXAsoaC1BW+qs4acp/hHpesweL6Rcg1pED
OJUQd3UvRsqRK0EsorDu0oj5wt6Qp3ZEbPMAEQEAAYkBHwQYAQIACQUCXVa78AIb
DAAKCRAAl2Pez8C7Uv8bB/9scRm2wvzHLbFtcEHaHvlKO1yYfSVqKqJzIKHc7pM2
+szM8JVRTxAbzK5Xih9SB5xlekixxO2UCJI5DkJ/ir/RCcg+/CAQ8iLm2UcYAgJD
TocKiR5gjNAvUDI4tMrDLLdF+7+RCQGc7HBSxFiNBJVGAztGVh1+cQ0zaCX6Tt33
1EQtyRcPID0m6+ip5tCJN0dILC0YcwzXGrSgjB03JqItIyJEucdQz6UB84TIAGku
JJl4tktgD9T7Rb5uzRhHCSbLy89DQVvCcKD4B94ffuDW3HO8n8utDusOiZuG4BUf
WdFy6/gTLNiFbTzkq1BBJQMN1nBwGs1sn63RRgjumZ1N
=dIcF
-----END PGP PUBLIC KEY BLOCK-----
</code></pre>
<h1><a class="header" href="#glossary" id="glossary">Glossary</a></h1>
<h3><a class="header" href="#blocking-1" id="blocking-1">blocking</a></h3>
<p>&quot;blocked&quot; generally refers to conditions that keep a task from doing its work. For example, it might need data to be sent by a client before continuing. When tasks become blocked, usually, other tasks are scheduled.</p>
<p>Sometimes you hear that you should never call &quot;blocking functions&quot; in an async context. What this refers to is functions that block the current thread and do not yield control back. This keeps the executor from using this thread to schedule another task.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
